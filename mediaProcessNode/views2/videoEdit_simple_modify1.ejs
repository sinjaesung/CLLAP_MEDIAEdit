<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link href="public/js_example_style.css" rel="stylesheet" type="text/css" />
    <script src='public/ffmpegwasm.js'></script>
    <style>
        html,body{
            margin:0;padding:0
        }
        .display_none{
            display:none;
        }
        canvas{
            background-color:#808080; display:none;
        }
        #imagesrc{
            outline:1px solid black; width:400px;height:400px;display:none;
        }

        .OUTPUT{
            width:100%;height:auto;border:1px solid blue;
        }

        /*비디오에디팅*/
        .editing_area{
            overflow:hidden;
        }
        #video_editing_area{
            width:100%;height:auto;margin:60px 0;background-color:rgba(80,200,240,0.8);position:relative;
        }
        .video_upload_area{
            width:100%;height:auto;display:block;overflow-x:auto;white-space:nowrap;background-color:#fff
        }
        .upload_video_element{
            border:2px solid red; overflow:hidden;width:20%;display:inline-block;position:relative;height:180px;width:20%;
        }
        .upload_video_element video{
            height:100%;height:auto;width:100%;position:relative;
        }
        .upload_video_element.plus video{
            height:auto;width:auto;
        }
        .upload_video_element.plus label{
            width:100%;height:auto;top:0;left:0;text-align:center;color:#fe8080;position:absolute;display:block;z-index:8
        }
       
        /*비디오수정room관련 영역*/
        .edit_room{
            background-color:rgba(120,50,220,0.8);padding-top:60px;padding-bottom:60px;position:relative;
        }
        .edit_room .take_row{
            position:relative;z-index:2;height:150px;border:1px dotted brown; display:none;
        }
        .edit_room .take_row_{
            position:relative;z-index:2;height:150px;border:1px dotted brown; display:none;
        }
        .edit_room h2{
            width:100%;height:30px;color:#fe8080;line-height:30px;margin:0;
        }
        .videotake_control{
            width:20%;height:120px;background-color:#000;position:absolute;left:0;bottom:0;
        }
        .videotake_original{
            width:40%;height:120px;background-color:rgba(50,60,240,0.8);
        }
        .videotake_control_{
            width:20%;height:120px;background-color:#000;position:absolute;left:0;bottom:0;
        }
       
        .video_left_duration_control{
            position:absolute;left:0;top:0;bottom:0;height:100%;width:15px;background-color:#aaa;transform:translateX(-50%);
        }   
        .video_right_duration_control{
            position:absolute;right:0;top:0;bottom:0;height:100%;width:15px;background-color:#aaa;transform:translateX(50%);
        }
        .video_left_duration_control img{
            position:absolute;top:50%;width:20px;height:20px;left:0;transform:translateY(-50%)
        }
       .video_right_duration_control img{
            position:absolute;top:50%;width:20px;height:20px;left:0;transform:translateY(-50%)rotate(180deg)
        }
        .videotake_control .time_info{
            width:100%;height:20px;line-height:20px;display:block;color:white; display:flex;flex-flow:row wrap;justify-content:center;align-items:center;
        }

        .timesecond_grid_area{
            width:100%; position:absolute;left:0;top:0;height:100%;z-index:0;display:flex;flex-flow:row nowrap;
        }
        .timesecond_grid_area .time_grid{
            width:calc(100% / 30);border-left:1px solid #fedf20;border-right:1px solid #fedf20;height:100%;color:white;display:flex;flex-flow:row wrap;align-items:flex-start;justify-content:center; font-size:8px;
        }
        
        .visible_range_cut{
            position:absolute;left:0;top:0;width:3.3%;height:100%;background-color:transparent;
        }

        /*비디오 인코딩 시간이 소요가 꽤 있기에 관련 progress*/
        #loading-progress{
            position:fixed;background-color:rgba(50,200,240,0.5);flex-flow:row wrap;justify-content:center;align-items:center;color:white;
            font-size:40px;font-weight:bold;display:none; width:50%;height:50%;z-index:9;left:50%;top:50%;transform:translateX(-50%)translateY(-50%)
        }
        #video_encodingprogress{
            position:fixed;background-color:rgba(50,200,240,0.5);flex-flow:row wrap;justify-content:center;align-items:center;color:white;
            font-size:40px;font-weight:bold;display:none; width:50%;height:50%;z-index:9;left:50%;top:50%;transform:translateX(-50%)translateY(-50%)
        }

        .takevideo_group_imglist img{
            display:block;
        }

        #canvasOutput_test{
            display:block;
        }
        #random_overlay_serveframesArea img{
            display:block !important;
        }
    </style>
    <style type="text/css">
    .dg {
        text-align: left;
    }
    .dg .property-name {
        font: 11px Lucida Grande,sans-serif;
        line-height: 27px;
    }
    .dg.main .close-button {
        font: 11px Lucida Grande,sans-serif;
        line-height: 27px;
    }
    .cell-top {
        vertical-align: top;
    }
    </style>
    <script src="/public/jquery.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/FileSaver.js/2.0.5/FileSaver.min.js"></script>

    <script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/stats.js/r16/Stats.min.js" type="text/javascript"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/dat-gui/0.6.4/dat.gui.min.js" type="text/javascript"></script>
    <script src="public/utils.js" type="text/javascript"></script>

</head>
<body>
<h2>OPENCV.JS OR OPENCVNODEJS AND FFMPEGNODE(spawn)</h2>
<p id='status'>OPENCV IS JIS LOADING....</p>

<p class="err" id="errorMessage"></p>
<div id="container">
    <p>영상을 출력하기전에 필터효과 미리 확인해보세요.</p>
    <table>
        <tr>
            <td></td>
            <td>
                <div>
                    <span>Current Filter: </span><span id="filterName">Pass Through</span>
                </div>
            </td>
            <td>
                <div>Select Filter:</div>
            </td>
            <td></td>
        </tr>
        <tr>
            <td></td>
            <td class="cell-top">
                <canvas id="canvasOutput_test" width="640" height="480"></canvas>
            </td>
            <td class="cell-top">
                <div id="guiContainer"></div>
            </td>
            <td></td>
        </tr>
    </table>
    <div>
        <video id="videoInput" width=640 height=480 src='resource/resource1.mp4' controls/>
    </div>
</div>

<p id='message' style='background-color:rgba(50,200,240,0.5);color:red'></p>
<p>이펙트 오버레이 선택</p>
<select id='select_overlay'>
    <option value='1'>overlay1</option>
    <option value='2'>overlay2</option>
    <option value='3'>overlay3</option>
    <option value='4'>overlay4</option>
    <option value='5'>overlay5</option>
    <option value='6'>overlay6</option>

</select>
<!--
<button id='overlay_captureing'>overlay capture</button>
<div class='inputoutput'>
    <video id='testvideo2' width=640 height=480 alt='no image' src='resource/resource1.mp4' controls></video>
    <video id='overlay1' width=640 height=480 alt='no image' src='resource/Particles/Particles_1.mp4'loop autoplay muted></video>  
    <video id='overlay2' width=640 height=480 alt='no image' src='resource/Particles/Particles_3.mp4'loop autoplay muted></video>
    <video id='overlay3' width=640 height=480 alt='no image' src='resource/Fireworks/Fireworks_3.mp4'loop autoplay muted></video>
    <video id='overlay4' width=640 height=480 alt='no image' src='resource/Fireworks/Fireworks_16.mp4'loop autoplay muted></video>
    <video id='overlay5' width=640 height=480 alt='no image' src='resource/Lens flare/Lens Flare 6.mp4'loop autoplay muted></video>
    <video id='overlay6' width=640 height=480 alt='no image' src='resource/Lens flare/Lens Flare 7.mp4'loop autoplay muted></video> 
    <video id='overlay7' width=640 height=480 alt='no image' src='resource/Rain/Rain_16.mp4'loop autoplay muted></video> 
    <video id='overlay8' width=640 height=480 alt='no image' src='resource/Rain/Rain_18.mp4' loop autoplay muted></video> 
    <video id='overlay9' width=640 height=480 alt='no image' src='resource/Smoke/Smoke_4.mp4' loop autoplay muted></video> 
    <video id='overlay10' width=640 height=480 alt='no image' src='resource/Smoke/Smoke_6.mp4'loop autoplay muted></video> 
</div>
<div class='inputoutput'>
    <div class='caption'>canvasinput</div>
    <canvas id='canvasinput00' style='display:block !important;'></canvas>
    <canvas id='canvasinput01' style='display:block !important;'></canvas>
</div>-->

<div class='inputoutput'>
    <div class='caption'>canvasOutput</div>
    <canvas id='canvasoutput00' style='display:block !important;'></canvas>
</div>

<div>
    <div id='loading-progress'>
        <span>processing...</span>
        <p>관련 연산 처리중입니다!..(트랜지션+필터&오버레이등..</p>
    </div>
    <div id='video_encodingprogress'>
        <span>processing...</span>
        <p>관련 연산 처리중입니다!..(업로드영상 인코딩중FFMPEG)</p>
    </div>

    <button id='test_extract'>이펙트처리(PROCESS)</button>
    <button id='original_to_videoEdit'>원본비디오 편집분할출력</button>
    <!--일련 작업 처리의 시작>>올린 영상들의 끝시작부분 각각 집합 이미지분할처리셋팅-->
    <form action='/testsss' id='image_extract_form'method='post'>
        <input type='hidden' name='upload_video_list' id='image_extract_form_data'/>
    </form>

    <p>video upload(1~5take select videos)</p>
    <form action='/upload_ver2' method='post' id='video_uploadform' onSubmit="javascript:return video_upload(event);">
        <input type='file' name='onetake' value='onetake'/>
        <input type='file' name='twotake' value='twotake'/>
        <input type='file' name='threetake' value='threetake'/>
        <input type='file' name='fourtake' value='fourtake'/>
        <input type='file' name='fivetake' value='fivetake'/>

        <input type='submit' value='업로드&인코딩'/>
    </form>
    <input type='hidden' name='upload_encoded_form_data' id='upload_encoded_form_data'/>
    <input type='hidden' name='upload_encoded_folderfilepathdata' id='upload_encoded_folderfilepathdata'/>
    
    <div class='inputoutput'>
        <video id='upload_edited_video0' width=640 height=360 alt='no image' src='' controls></video>
        <video id='upload_edited_video1' width=640 height=360 alt='no image' src='' controls></video>
        <video id='upload_edited_video2' width=640 height=360 alt='no image' src='' controls></video>
        <video id='upload_edited_video3' width=640 height=360 alt='no image' src='' controls></video>
        <video id='upload_edited_video4' width=640 height=360 alt='no image' src='' controls></video>
    </div>
    <div class='OUTPUT'>
        <video id='output_video_element' width=640 height=360 alt='no image' src='' controls></video>
    </div>

    <div class='inputoutput'>
        <div class='caption'>canvasinput</div>
        <canvas id='canvasinput1'></canvas>
        <canvas id='canvasinput2'></canvas>

        <!--canvas img data areass display:none transition areass....-->
        <canvas id='canvasinput1-1' ></canvas>
        <canvas id='canvasinput1-2'></canvas>
        <canvas id='canvasinput1-3'></canvas>
        <canvas id='canvasinput1-4'></canvas>
        <canvas id='canvasinput1-5'></canvas>
        <canvas id='canvasinput1-6'class=''></canvas>
        <canvas id='canvasinput1-7'class=''></canvas>
        <canvas id='canvasinput1-8'class=''></canvas>
        <canvas id='canvasinput1-9'class=''></canvas>
        <canvas id='canvasinput1-10'class=''></canvas>
        <canvas id='canvasinput1-11'class=''></canvas>
        <canvas id='canvasinput1-12'class=''></canvas>
        <canvas id='canvasinput1-13'class=''></canvas>
        <canvas id='canvasinput1-14'class=''></canvas>
        <canvas id='canvasinput1-15'class=''></canvas>
        <canvas id='canvasinput1-16'class=''></canvas>
        <canvas id='canvasinput1-17'class=''></canvas>
        <canvas id='canvasinput1-18'class=''></canvas>
        <canvas id='canvasinput1-19'class=''></canvas>
        <canvas id='canvasinput1-20'class=''></canvas>
        <canvas id='canvasinput1-21'class=''></canvas>
        <canvas id='canvasinput1-22'class=''></canvas>
        <canvas id='canvasinput1-23'class=''></canvas>
        <canvas id='canvasinput1-24'class=''></canvas>
        <canvas id='canvasinput1-25'class=''></canvas>
        <canvas id='canvasinput1-26'class=''></canvas>
        <canvas id='canvasinput1-27'class=''></canvas>
        <canvas id='canvasinput1-28'class=''></canvas>
        <canvas id='canvasinput1-29'class=''></canvas>
        <canvas id='canvasinput1-30'class=''></canvas>
        <canvas id='canvasinput1-31'class='display_none'></canvas>
        <canvas id='canvasinput1-32'class='display_none'></canvas>
        <canvas id='canvasinput1-33'class='display_none'></canvas>
        <canvas id='canvasinput1-34'class='display_none'></canvas>
        <canvas id='canvasinput1-35'class='display_none'></canvas>
        <canvas id='canvasinput1-36'class='display_none'></canvas>
        <canvas id='canvasinput1-37'class='display_none'></canvas>
        <canvas id='canvasinput1-38'class='display_none'></canvas>
        <canvas id='canvasinput1-39'class='display_none'></canvas>
        <canvas id='canvasinput1-40'class='display_none'></canvas>
        <canvas id='canvasinput1-41'class='display_none'></canvas>
        <canvas id='canvasinput1-42'class='display_none'></canvas>
        <canvas id='canvasinput1-43'class='display_none'></canvas>
        <canvas id='canvasinput1-44'class='display_none'></canvas>
        <canvas id='canvasinput1-45'class='display_none'></canvas>
        <canvas id='canvasinput1-46'class='display_none'></canvas>
        <canvas id='canvasinput1-47'class='display_none'></canvas>
        <canvas id='canvasinput1-48'class='display_none'></canvas>
        <canvas id='canvasinput1-49'class='display_none'></canvas>
        <canvas id='canvasinput1-50'class='display_none'></canvas>
        <canvas id='canvasinput1-51'class='display_none'></canvas>
        <canvas id='canvasinput1-52'class='display_none'></canvas>
        <canvas id='canvasinput1-53'class='display_none'></canvas>
        <canvas id='canvasinput1-54'class='display_none'></canvas>
        <canvas id='canvasinput1-55'class='display_none'></canvas>
        <canvas id='canvasinput1-56'class='display_none'></canvas>
        <canvas id='canvasinput1-57'class='display_none'></canvas>
        <canvas id='canvasinput1-58'class='display_none'></canvas>
        <canvas id='canvasinput1-59'class='display_none'></canvas>
        <canvas id='canvasinput1-60'class='display_none'></canvas>


        <canvas id='canvasinput1-61'class='display_none'></canvas>
        <canvas id='canvasinput1-62'class='display_none'></canvas>
        <canvas id='canvasinput1-63'class='display_none'></canvas>
        <canvas id='canvasinput1-64'class='display_none'></canvas>
        <canvas id='canvasinput1-65'class='display_none'></canvas>
        <canvas id='canvasinput1-66'class='display_none'></canvas>
        <canvas id='canvasinput1-67'class='display_none'></canvas>
        <canvas id='canvasinput1-68'class='display_none'></canvas>
        <canvas id='canvasinput1-69'class='display_none'></canvas>
        <canvas id='canvasinput1-70'class='display_none'></canvas>
        <canvas id='canvasinput1-71'class='display_none'></canvas>
        <canvas id='canvasinput1-72'class='display_none'></canvas>
        <canvas id='canvasinput1-73'class='display_none'></canvas>
        <canvas id='canvasinput1-74'class='display_none'></canvas>
        <canvas id='canvasinput1-75'class='display_none'></canvas>
        <canvas id='canvasinput1-76'class='display_none'></canvas>
        <canvas id='canvasinput1-77'class='display_none'></canvas>
        <canvas id='canvasinput1-78'class='display_none'></canvas>
        <canvas id='canvasinput1-79'class='display_none'></canvas>
        <canvas id='canvasinput1-80'class='display_none'></canvas>
        <canvas id='canvasinput1-81'class='display_none'></canvas>
        <canvas id='canvasinput1-82'class='display_none'></canvas>
        <canvas id='canvasinput1-83'class='display_none'></canvas>
        <canvas id='canvasinput1-84'class='display_none'></canvas>
        <canvas id='canvasinput1-85'class='display_none'></canvas>
        <canvas id='canvasinput1-86'class='display_none'></canvas>
        <canvas id='canvasinput1-87'class='display_none'></canvas>
        <canvas id='canvasinput1-88'class='display_none'></canvas>
        <canvas id='canvasinput1-89'class='display_none'></canvas>
        <canvas id='canvasinput1-90'class='display_none'></canvas>
        <canvas id='canvasinput1-91'class='display_none'></canvas>
        <canvas id='canvasinput1-92'class='display_none'></canvas>
        <canvas id='canvasinput1-93'class='display_none'></canvas>
        <canvas id='canvasinput1-94'class='display_none'></canvas>
        <canvas id='canvasinput1-95'class='display_none'></canvas>
        <canvas id='canvasinput1-96'class='display_none'></canvas>
        <canvas id='canvasinput1-97'class='display_none'></canvas>
        <canvas id='canvasinput1-98'class='display_none'></canvas>
        <canvas id='canvasinput1-99'class='display_none'></canvas>
        <canvas id='canvasinput1-100'class='display_none'></canvas>
        <canvas id='canvasinput1-101'class='display_none'></canvas>
        <canvas id='canvasinput1-102'class='display_none'></canvas>
        <canvas id='canvasinput1-103'class='display_none'></canvas>
        <canvas id='canvasinput1-104'class='display_none'></canvas>
        <canvas id='canvasinput1-105'class='display_none'></canvas>
        <canvas id='canvasinput1-106'class='display_none'></canvas>
        <canvas id='canvasinput1-107'class='display_none'></canvas>
        <canvas id='canvasinput1-108'class='display_none'></canvas>
        <canvas id='canvasinput1-109'class='display_none'></canvas>
        <canvas id='canvasinput1-110'class='display_none'></canvas>
        <canvas id='canvasinput1-111'class='display_none'></canvas>
        <canvas id='canvasinput1-112'class='display_none'></canvas>
        <canvas id='canvasinput1-113'class='display_none'></canvas>
        <canvas id='canvasinput1-114'class='display_none'></canvas>
        <canvas id='canvasinput1-115'class='display_none'></canvas>
        <canvas id='canvasinput1-116'class='display_none'></canvas>
        <canvas id='canvasinput1-117'class='display_none'></canvas>
        <canvas id='canvasinput1-118'class='display_none'></canvas>
        <canvas id='canvasinput1-119'class='display_none'></canvas>
        <canvas id='canvasinput1-120'class='display_none'></canvas>

        <canvas id='canvasinput1-121'class='display_none'></canvas>
        <canvas id='canvasinput1-122'class='display_none'></canvas>
        <canvas id='canvasinput1-123'class='display_none'></canvas>
        <canvas id='canvasinput1-124'class='display_none'></canvas>
        <canvas id='canvasinput1-125'class='display_none'></canvas>
        <canvas id='canvasinput1-126'class='display_none'></canvas>
        <canvas id='canvasinput1-127'class='display_none'></canvas>
        <canvas id='canvasinput1-128'class='display_none'></canvas>
        <canvas id='canvasinput1-129'class='display_none'></canvas>
        <canvas id='canvasinput1-130'class='display_none'></canvas>
        <canvas id='canvasinput1-131'class='display_none'></canvas>
        <canvas id='canvasinput1-132'class='display_none'></canvas>
        <canvas id='canvasinput1-133'class='display_none'></canvas>
        <canvas id='canvasinput1-134'class='display_none'></canvas>
        <canvas id='canvasinput1-135'class='display_none'></canvas>
        <canvas id='canvasinput1-136'class='display_none'></canvas>
        <canvas id='canvasinput1-137'class='display_none'></canvas>
        <canvas id='canvasinput1-138'class='display_none'></canvas>
        <canvas id='canvasinput1-139'class='display_none'></canvas>
        <canvas id='canvasinput1-140'class='display_none'></canvas>
        <canvas id='canvasinput1-141'class='display_none'></canvas>
        <canvas id='canvasinput1-142'class='display_none'></canvas>
        <canvas id='canvasinput1-143'class='display_none'></canvas>
        <canvas id='canvasinput1-144'class='display_none'></canvas>
        <canvas id='canvasinput1-145'class='display_none'></canvas>
        <canvas id='canvasinput1-146'class='display_none'></canvas>
        <canvas id='canvasinput1-147'class='display_none'></canvas>
        <canvas id='canvasinput1-148'class='display_none'></canvas>
        <canvas id='canvasinput1-149'class='display_none'></canvas>
        <canvas id='canvasinput1-150'class='display_none'></canvas>
        <canvas id='canvasinput1-151'class='display_none'></canvas>
        <canvas id='canvasinput1-152'class='display_none'></canvas>
        <canvas id='canvasinput1-153'class='display_none'></canvas>
        <canvas id='canvasinput1-154'class='display_none'></canvas>
        <canvas id='canvasinput1-155'class='display_none'></canvas>
        <canvas id='canvasinput1-156'class='display_none'></canvas>
        <canvas id='canvasinput1-157'class='display_none'></canvas>
        <canvas id='canvasinput1-158'class='display_none'></canvas>
        <canvas id='canvasinput1-159'class='display_none'></canvas>
        <canvas id='canvasinput1-160'class='display_none'></canvas>
        <canvas id='canvasinput1-161'class='display_none'></canvas>
        <canvas id='canvasinput1-162'class='display_none'></canvas>
        <canvas id='canvasinput1-163'class='display_none'></canvas>
        <canvas id='canvasinput1-164'class='display_none'></canvas>
        <canvas id='canvasinput1-165'class='display_none'></canvas>
        <canvas id='canvasinput1-166'class='display_none'></canvas>
        <canvas id='canvasinput1-167'class='display_none'></canvas>
        <canvas id='canvasinput1-168'class='display_none'></canvas>
        <canvas id='canvasinput1-169'class='display_none'></canvas>
        <canvas id='canvasinput1-170'class='display_none'></canvas>
        <canvas id='canvasinput1-171'class='display_none'></canvas>
        <canvas id='canvasinput1-172'class='display_none'></canvas>
        <canvas id='canvasinput1-173'class='display_none'></canvas>
        <canvas id='canvasinput1-174'class='display_none'></canvas>
        <canvas id='canvasinput1-175'class='display_none'></canvas>
        <canvas id='canvasinput1-176'class='display_none'></canvas>
        <canvas id='canvasinput1-177'class='display_none'></canvas>
        <canvas id='canvasinput1-178'class='display_none'></canvas>
        <canvas id='canvasinput1-179'class='display_none'></canvas>
        <canvas id='canvasinput1-180'class='display_none'></canvas>


        <canvas id='canvasinput1-181'class='display_none'></canvas>
        <canvas id='canvasinput1-182'class='display_none'></canvas>
        <canvas id='canvasinput1-183'class='display_none'></canvas>
        <canvas id='canvasinput1-184'class='display_none'></canvas>
        <canvas id='canvasinput1-185'class='display_none'></canvas>
        <canvas id='canvasinput1-186'class='display_none'></canvas>
        <canvas id='canvasinput1-187'class='display_none'></canvas>
        <canvas id='canvasinput1-188'class='display_none'></canvas>
        <canvas id='canvasinput1-189'class='display_none'></canvas>
        <canvas id='canvasinput1-190'class='display_none'></canvas>
        <canvas id='canvasinput1-191'class='display_none'></canvas>
        <canvas id='canvasinput1-192'class='display_none'></canvas>
        <canvas id='canvasinput1-193'class='display_none'></canvas>
        <canvas id='canvasinput1-194'class='display_none'></canvas>
        <canvas id='canvasinput1-195'class='display_none'></canvas>
        <canvas id='canvasinput1-196'class='display_none'></canvas>
        <canvas id='canvasinput1-197'class='display_none'></canvas>
        <canvas id='canvasinput1-198'class='display_none'></canvas>
        <canvas id='canvasinput1-199'class='display_none'></canvas>
        <canvas id='canvasinput1-200'class='display_none'></canvas>
        <canvas id='canvasinput1-201'class='display_none'></canvas>
        <canvas id='canvasinput1-202'class='display_none'></canvas>
        <canvas id='canvasinput1-203'class='display_none'></canvas>
        <canvas id='canvasinput1-204'class='display_none'></canvas>
        <canvas id='canvasinput1-205'class='display_none'></canvas>
        <canvas id='canvasinput1-206'class='display_none'></canvas>
        <canvas id='canvasinput1-207'class='display_none'></canvas>
        <canvas id='canvasinput1-208'class='display_none'></canvas>
        <canvas id='canvasinput1-209'class='display_none'></canvas>
        <canvas id='canvasinput1-210'class='display_none'></canvas>
        <canvas id='canvasinput1-211'class='display_none'></canvas>
        <canvas id='canvasinput1-212'class='display_none'></canvas>
        <canvas id='canvasinput1-213'class='display_none'></canvas>
        <canvas id='canvasinput1-214'class='display_none'></canvas>
        <canvas id='canvasinput1-215'class='display_none'></canvas>
        <canvas id='canvasinput1-216'class='display_none'></canvas>
        <canvas id='canvasinput1-217'class='display_none'></canvas>
        <canvas id='canvasinput1-218'class='display_none'></canvas>
        <canvas id='canvasinput1-219'class='display_none'></canvas>
        <canvas id='canvasinput1-220'class='display_none'></canvas>
        <canvas id='canvasinput1-221'class='display_none'></canvas>
        <canvas id='canvasinput1-222'class='display_none'></canvas>
        <canvas id='canvasinput1-223'class='display_none'></canvas>
        <canvas id='canvasinput1-224'class='display_none'></canvas>
        <canvas id='canvasinput1-225'class='display_none'></canvas>
        <canvas id='canvasinput1-226'class='display_none'></canvas>
        <canvas id='canvasinput1-227'class='display_none'></canvas>
        <canvas id='canvasinput1-228'class='display_none'></canvas>
        <canvas id='canvasinput1-229'class='display_none'></canvas>
        <canvas id='canvasinput1-230'class='display_none'></canvas>
        <canvas id='canvasinput1-231'class='display_none'></canvas>
        <canvas id='canvasinput1-232'class='display_none'></canvas>
        <canvas id='canvasinput1-233'class='display_none'></canvas>
        <canvas id='canvasinput1-234'class='display_none'></canvas>
        <canvas id='canvasinput1-235'class='display_none'></canvas>
        <canvas id='canvasinput1-236'class='display_none'></canvas>
        <canvas id='canvasinput1-237'class='display_none'></canvas>
        <canvas id='canvasinput1-238'class='display_none'></canvas>
        <canvas id='canvasinput1-239'class='display_none'></canvas>
        <canvas id='canvasinput1-240'class='display_none'></canvas>
    </div>
    <!--overlay or filter effect canvasinput elements...-->
    <div>
        <canvas id='canvasinput_effect1'></canvas>
        <canvas id='canvasinput_effect2'></canvas>
        <canvas id='canvasinput_effect3'></canvas>
        <canvas id='canvasinput_effect4'></canvas>
        <canvas id='canvasinput_effect5'></canvas>
        <canvas id='canvasinput_effect6'></canvas>
        <canvas id='canvasinput_effect7'></canvas>
        <canvas id='canvasinput_effect8'></canvas>
        <canvas id='canvasinput_effect9'></canvas>
        <canvas id='canvasinput_effect10'></canvas>
        <canvas id='canvasinput_effect11'></canvas>
        <canvas id='canvasinput_effect12'></canvas>
        <canvas id='canvasinput_effect13'></canvas>
        <canvas id='canvasinput_effect14'></canvas>
        <canvas id='canvasinput_effect15'></canvas>
        <canvas id='canvasinput_effect16'></canvas>
        <canvas id='canvasinput_effect17'></canvas>
        <canvas id='canvasinput_effect18'></canvas>
        <canvas id='canvasinput_effect19'></canvas>
        <canvas id='canvasinput_effect20'></canvas>
        <canvas id='canvasinput_effect21'></canvas>
        <canvas id='canvasinput_effect22'></canvas>
        <canvas id='canvasinput_effect23'></canvas>
        <canvas id='canvasinput_effect24'></canvas>
        <canvas id='canvasinput_effect25'></canvas>
        <canvas id='canvasinput_effect26'></canvas>
        <canvas id='canvasinput_effect27'></canvas>
        <canvas id='canvasinput_effect28'></canvas>
        <canvas id='canvasinput_effect29'></canvas>
        <canvas id='canvasinput_effect30'></canvas>
        <canvas id='canvasinput_effect31'></canvas>
        <canvas id='canvasinput_effect32'></canvas>
        <canvas id='canvasinput_effect33'></canvas>
        <canvas id='canvasinput_effect34'></canvas>
        <canvas id='canvasinput_effect35'></canvas>
        <canvas id='canvasinput_effect36'></canvas>
        <canvas id='canvasinput_effect37'></canvas>
        <canvas id='canvasinput_effect38'></canvas>
        <canvas id='canvasinput_effect39'></canvas>
        <canvas id='canvasinput_effect40'></canvas>
        <canvas id='canvasinput_effect41'></canvas>
        <canvas id='canvasinput_effect42'></canvas>
        <canvas id='canvasinput_effect43'></canvas>
        <canvas id='canvasinput_effect44'></canvas>
        <canvas id='canvasinput_effect45'></canvas>
        <canvas id='canvasinput_effect46'></canvas>
        <canvas id='canvasinput_effect47'></canvas>
        <canvas id='canvasinput_effect48'></canvas>
        <canvas id='canvasinput_effect49'></canvas>
        <canvas id='canvasinput_effect50'></canvas>
        <canvas id='canvasinput_effect51'></canvas>
        <canvas id='canvasinput_effect52'></canvas>
        <canvas id='canvasinput_effect53'></canvas>
        <canvas id='canvasinput_effect54'></canvas>
        <canvas id='canvasinput_effect55'></canvas>
        <canvas id='canvasinput_effect56'></canvas>
        <canvas id='canvasinput_effect57'></canvas>
        <canvas id='canvasinput_effect58'></canvas>
        <canvas id='canvasinput_effect59'></canvas>
        <canvas id='canvasinput_effect60'></canvas>
        <canvas id='canvasinput_effect61'></canvas>
        <canvas id='canvasinput_effect62'></canvas>
        <canvas id='canvasinput_effect63'></canvas>
        <canvas id='canvasinput_effect64'></canvas>
        <canvas id='canvasinput_effect65'></canvas>
        <canvas id='canvasinput_effect66'></canvas>
        <canvas id='canvasinput_effect67'></canvas>
        <canvas id='canvasinput_effect68'></canvas>
        <canvas id='canvasinput_effect69'></canvas>
        <canvas id='canvasinput_effect70'></canvas>
        <canvas id='canvasinput_effect71'></canvas>
        <canvas id='canvasinput_effect72'></canvas>
        <canvas id='canvasinput_effect73'></canvas>
        <canvas id='canvasinput_effect74'></canvas>
        <canvas id='canvasinput_effect75'></canvas>
        <canvas id='canvasinput_effect76'></canvas>
        <canvas id='canvasinput_effect77'></canvas>
        <canvas id='canvasinput_effect78'></canvas>
        <canvas id='canvasinput_effect79'></canvas>
        <canvas id='canvasinput_effect80'></canvas>
        <canvas id='canvasinput_effect81'></canvas>
        <canvas id='canvasinput_effect82'></canvas>
        <canvas id='canvasinput_effect83'></canvas>
        <canvas id='canvasinput_effect84'></canvas>
        <canvas id='canvasinput_effect85'></canvas>
        <canvas id='canvasinput_effect86'></canvas>
        <canvas id='canvasinput_effect87'></canvas>
        <canvas id='canvasinput_effect88'></canvas>
        <canvas id='canvasinput_effect89'></canvas>
        <canvas id='canvasinput_effect90'></canvas>
        <canvas id='canvasinput_effect91'></canvas>
        <canvas id='canvasinput_effect92'></canvas>
        <canvas id='canvasinput_effect93'></canvas>
        <canvas id='canvasinput_effect94'></canvas>
        <canvas id='canvasinput_effect95'></canvas>
        <canvas id='canvasinput_effect96'></canvas>
        <canvas id='canvasinput_effect97'></canvas>
        <canvas id='canvasinput_effect98'></canvas>
        <canvas id='canvasinput_effect99'></canvas>
        <canvas id='canvasinput_effect100'></canvas>
        <canvas id='canvasinput_effect101'></canvas>
        <canvas id='canvasinput_effect102'></canvas>
        <canvas id='canvasinput_effect103'></canvas>
        <canvas id='canvasinput_effect104'></canvas>
        <canvas id='canvasinput_effect105'></canvas>
        <canvas id='canvasinput_effect106'></canvas>
        <canvas id='canvasinput_effect107'></canvas>
        <canvas id='canvasinput_effect108'></canvas>
        <canvas id='canvasinput_effect109'></canvas>
        <canvas id='canvasinput_effect110'></canvas>
        <canvas id='canvasinput_effect111'></canvas>
        <canvas id='canvasinput_effect112'></canvas>
        <canvas id='canvasinput_effect113'></canvas>
        <canvas id='canvasinput_effect114'></canvas>
        <canvas id='canvasinput_effect115'></canvas>
        <canvas id='canvasinput_effect116'></canvas>
        <canvas id='canvasinput_effect117'></canvas>
        <canvas id='canvasinput_effect118'></canvas>
        <canvas id='canvasinput_effect119'></canvas>
        <canvas id='canvasinput_effect120'></canvas>
        <canvas id='canvasinput_effect121'></canvas>
        <canvas id='canvasinput_effect121'></canvas>
        <canvas id='canvasinput_effect122'></canvas>
        <canvas id='canvasinput_effect123'></canvas>
        <canvas id='canvasinput_effect124'></canvas>
        <canvas id='canvasinput_effect125'></canvas>
        <canvas id='canvasinput_effect126'></canvas>
        <canvas id='canvasinput_effect127'></canvas>
        <canvas id='canvasinput_effect128'></canvas>
        <canvas id='canvasinput_effect129'></canvas>
        <canvas id='canvasinput_effect130'></canvas>
        <canvas id='canvasinput_effect131'></canvas>
        <canvas id='canvasinput_effect132'></canvas>
        <canvas id='canvasinput_effect133'></canvas>
        <canvas id='canvasinput_effect134'></canvas>
        <canvas id='canvasinput_effect135'></canvas>
        <canvas id='canvasinput_effect136'></canvas>
        <canvas id='canvasinput_effect137'></canvas>
        <canvas id='canvasinput_effect138'></canvas>
        <canvas id='canvasinput_effect139'></canvas>
        <canvas id='canvasinput_effect140'></canvas>
        <canvas id='canvasinput_effect141'></canvas>
        <canvas id='canvasinput_effect142'></canvas>
        <canvas id='canvasinput_effect143'></canvas>
        <canvas id='canvasinput_effect144'></canvas>
        <canvas id='canvasinput_effect145'></canvas>
        <canvas id='canvasinput_effect146'></canvas>
        <canvas id='canvasinput_effect147'></canvas>
        <canvas id='canvasinput_effect148'></canvas>
        <canvas id='canvasinput_effect149'></canvas>
        <canvas id='canvasinput_effect150'></canvas>
        <canvas id='canvasinput_effect151'></canvas>
        <canvas id='canvasinput_effect152'></canvas>
        <canvas id='canvasinput_effect153'></canvas>
        <canvas id='canvasinput_effect154'></canvas>
        <canvas id='canvasinput_effect155'></canvas>
        <canvas id='canvasinput_effect156'></canvas>
        <canvas id='canvasinput_effect157'></canvas>
        <canvas id='canvasinput_effect158'></canvas>
        <canvas id='canvasinput_effect159'></canvas>
        <canvas id='canvasinput_effect160'></canvas>
        <canvas id='canvasinput_effect160'></canvas>
        <canvas id='canvasinput_effect161'></canvas>
        <canvas id='canvasinput_effect162'></canvas>
        <canvas id='canvasinput_effect163'></canvas>
        <canvas id='canvasinput_effect164'></canvas>
        <canvas id='canvasinput_effect165'></canvas>
        <canvas id='canvasinput_effect166'></canvas>
        <canvas id='canvasinput_effect167'></canvas>
        <canvas id='canvasinput_effect168'></canvas>
        <canvas id='canvasinput_effect169'></canvas>
        <canvas id='canvasinput_effect170'></canvas>
        <canvas id='canvasinput_effect171'></canvas>
        <canvas id='canvasinput_effect172'></canvas>
        <canvas id='canvasinput_effect173'></canvas>
        <canvas id='canvasinput_effect174'></canvas>
        <canvas id='canvasinput_effect175'></canvas>
        <canvas id='canvasinput_effect176'></canvas>
        <canvas id='canvasinput_effect177'></canvas>
        <canvas id='canvasinput_effect178'></canvas>
        <canvas id='canvasinput_effect179'></canvas>
        <canvas id='canvasinput_effect180'></canvas>
        <canvas id='canvasinput_effect180'></canvas>
        <canvas id='canvasinput_effect181'></canvas>
        <canvas id='canvasinput_effect182'></canvas>
        <canvas id='canvasinput_effect183'></canvas>
        <canvas id='canvasinput_effect184'></canvas>
        <canvas id='canvasinput_effect185'></canvas>
        <canvas id='canvasinput_effect186'></canvas>
        <canvas id='canvasinput_effect187'></canvas>
        <canvas id='canvasinput_effect188'></canvas>
        <canvas id='canvasinput_effect189'></canvas>
        <canvas id='canvasinput_effect190'></canvas>
        <canvas id='canvasinput_effect191'></canvas>
        <canvas id='canvasinput_effect192'></canvas>
        <canvas id='canvasinput_effect193'></canvas>
        <canvas id='canvasinput_effect194'></canvas>
        <canvas id='canvasinput_effect195'></canvas>
        <canvas id='canvasinput_effect196'></canvas>
        <canvas id='canvasinput_effect197'></canvas>
        <canvas id='canvasinput_effect198'></canvas>
        <canvas id='canvasinput_effect199'></canvas>
        <canvas id='canvasinput_effect200'></canvas>
        <canvas id='canvasinput_effect201'></canvas>
        <canvas id='canvasinput_effect202'></canvas>
        <canvas id='canvasinput_effect203'></canvas>
        <canvas id='canvasinput_effect204'></canvas>
        <canvas id='canvasinput_effect205'></canvas>
        <canvas id='canvasinput_effect206'></canvas>
        <canvas id='canvasinput_effect207'></canvas>
        <canvas id='canvasinput_effect208'></canvas>
        <canvas id='canvasinput_effect209'></canvas>
        <canvas id='canvasinput_effect210'></canvas>
        <canvas id='canvasinput_effect211'></canvas>
        <canvas id='canvasinput_effect212'></canvas>
        <canvas id='canvasinput_effect213'></canvas>
        <canvas id='canvasinput_effect214'></canvas>
        <canvas id='canvasinput_effect215'></canvas>
        <canvas id='canvasinput_effect216'></canvas>
        <canvas id='canvasinput_effect217'></canvas>
        <canvas id='canvasinput_effect218'></canvas>
        <canvas id='canvasinput_effect219'></canvas>
        <canvas id='canvasinput_effect220'></canvas>
        <canvas id='canvasinput_effect221'></canvas>
        <canvas id='canvasinput_effect222'></canvas>
        <canvas id='canvasinput_effect223'></canvas>
        <canvas id='canvasinput_effect224'></canvas>
        <canvas id='canvasinput_effect225'></canvas>
        <canvas id='canvasinput_effect226'></canvas>
        <canvas id='canvasinput_effect227'></canvas>
        <canvas id='canvasinput_effect228'></canvas>
        <canvas id='canvasinput_effect229'></canvas>
        <canvas id='canvasinput_effect230'></canvas>
        <canvas id='canvasinput_effect231'></canvas>
        <canvas id='canvasinput_effect232'></canvas>
        <canvas id='canvasinput_effect233'></canvas>
        <canvas id='canvasinput_effect234'></canvas>
        <canvas id='canvasinput_effect235'></canvas>
        <canvas id='canvasinput_effect236'></canvas>
        <canvas id='canvasinput_effect237'></canvas>
        <canvas id='canvasinput_effect238'></canvas>
        <canvas id='canvasinput_effect239'></canvas>
        <canvas id='canvasinput_effect240'></canvas>
        <canvas id='canvasinput_effect240'></canvas>
        <canvas id='canvasinput_effect241'></canvas>
        <canvas id='canvasinput_effect242'></canvas>
        <canvas id='canvasinput_effect243'></canvas>
        <canvas id='canvasinput_effect244'></canvas>
        <canvas id='canvasinput_effect245'></canvas>
        <canvas id='canvasinput_effect246'></canvas>
        <canvas id='canvasinput_effect247'></canvas>
        <canvas id='canvasinput_effect248'></canvas>
        <canvas id='canvasinput_effect249'></canvas>
        <canvas id='canvasinput_effect250'></canvas>
        <canvas id='canvasinput_effect251'></canvas>
        <canvas id='canvasinput_effect252'></canvas>
        <canvas id='canvasinput_effect253'></canvas>
        <canvas id='canvasinput_effect254'></canvas>
        <canvas id='canvasinput_effect255'></canvas>
        <canvas id='canvasinput_effect256'></canvas>
        <canvas id='canvasinput_effect257'></canvas>
        <canvas id='canvasinput_effect258'></canvas>
        <canvas id='canvasinput_effect259'></canvas>
        <canvas id='canvasinput_effect260'></canvas>
        <canvas id='canvasinput_effect261'></canvas>
        <canvas id='canvasinput_effect262'></canvas>
        <canvas id='canvasinput_effect263'></canvas>
        <canvas id='canvasinput_effect264'></canvas>
        <canvas id='canvasinput_effect265'></canvas>
        <canvas id='canvasinput_effect266'></canvas>
        <canvas id='canvasinput_effect267'></canvas>
        <canvas id='canvasinput_effect268'></canvas>
        <canvas id='canvasinput_effect269'></canvas>
        <canvas id='canvasinput_effect270'></canvas>
    </div>

    <div id='canvasinput_takevideo_wrap'>
    </div>

    </div>
    <div id='video_between_transition_startendArea'>
    </div>
    <div id='take_video_imgpart_total'>
    </div>
    <div id='random_overlay_serveframesArea'>
    </div>

    <div id='video_editing_area' class='editing_area'>
        <h3>원본영상에서 자르고싶은 부분적인 길이/위치구간 지정</h3>
        <div class='video_upload_area'>
            <div id='take1_video' class='upload_video_element'>
                <video id='upload_video0' src='' width=320 height=180 controls></video>
            </div>
            <div id='take2_video'class='upload_video_element'>
                <video id='upload_video1' src='' width=320 height=180 controls></video>
            </div>
            <div id='take3_video'class='upload_video_element'>
                <video id='upload_video2' src='' width=320 height=180 controls></video>
            </div>
            <div id='take4_video'class='upload_video_element'>
                <video id='upload_video3' src='' width=320 height=180 controls></video>
            </div>
            <div id='take5_video'class='upload_video_element'>
                <video id='upload_video4' src='' width=320 height=180 controls></video>
            </div>
        </div>
        <div class='edit_room'>
            <div class='timesecond_grid_area'>
                <div class='time_grid' id='index1'>
                    0~1(s)
                </div>
                <div class='time_grid'id='index2'>
                    1~2(s)
                </div>
                <div class='time_grid'id='index3'>
                    2~3(s)
                </div>
                <div class='time_grid'id='index4'>
                    3~4(s)
                </div>
                <div class='time_grid'id='index5'>
                    4~5(s)
                </div>
                <div class='time_grid'id='index6'>
                    5~6(s)
                </div>
                <div class='time_grid'id='index7'>
                    6~7(s)
                </div>
                <div class='time_grid'id='index8'>
                    7~8(s)
                </div>
                <div class='time_grid'id='index9'>
                    8~9(s)
                </div>
                <div class='time_grid'id='index10'>
                    9~10(s)
                </div>
                <div class='time_grid'id='index11'>
                    10~11(s)
                </div>
                <div class='time_grid'id='index12'>
                    11~12(s)
                </div>
                <div class='time_grid'id='index13'>
                    12~13(s)
                </div>
                <div class='time_grid'id='index14'>
                    13~14(s)
                </div>
                <div class='time_grid'id='index15'>
                    14~15(s)
                </div>
                <div class='time_grid'id='index16'>
                    15~16(s)
                </div>
                <div class='time_grid'id='index17'>
                    16~17(s)
                </div>
                <div class='time_grid'id='index18'>
                    17~18(s)
                </div>
                <div class='time_grid'id='index19'>
                    18~19(s)
                </div>
                <div class='time_grid'id='index20'>
                    19~20(s)
                </div>
                <div class='time_grid'id='index21'>
                    20~21(s)
                </div>
                <div class='time_grid'id='index22'>
                    21~22(s)
                </div>
                <div class='time_grid'id='index23'>
                    22~23(s)
                </div>
                <div class='time_grid'id='index24'>
                    23~24(s)
                </div>
                <div class='time_grid'id='index25'>
                    24~25(s)
                </div>
                <div class='time_grid'id='index26'>
                    25~26(s)
                </div>
                <div class='time_grid'id='index27'>
                    26~27(s)
                </div>
                <div class='time_grid'id='index28'>
                    27~28(s)
                </div>
                <div class='time_grid'id='index29'>
                    28~29(s)
                </div>
                <div class='time_grid'id='index30'>
                    29~30(s)
                </div>             
            </div>
            <div class='take_row' id='take1_area'>
                <h2>TAKE1</h2>
                <div class='videotake_control' dataset-take=1 id='control1' original_duration=20 change_duration=20 startpos=0 endpos=0>
                    <span class='time_info' id='control1_timeinfo'></span>
                    <div class='video_left_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                    <div class='video_right_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                </div>
            </div>
            <div class='take_row'id='take2_area'>
                <h2>TAKE2</h2>
                <div class='videotake_control' dataset-take=2 id='control2'original_duration=20 change_duration=20 startpos=0 endpos=0>
                    <span class='time_info' id='control2_timeinfo'></span>
                    <div class='video_left_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                    <div class='video_right_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                </div>
            </div>
            <div class='take_row'id='take3_area'>
                <h2>TAKE3</h2>
                <div class='videotake_control' dataset-take=3 id='control3'original_duration=16 change_duration=16 startpos=0 endpos=0>
                    <span class='time_info' id='control3_timeinfo'></span>
                    <div class='video_left_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                    <div class='video_right_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                </div>
            </div>
            <div class='take_row'id='take4_area'>
                <h2>TAKE4</h2>
                <div class='videotake_control' dataset-take=4 id='control4'original_duration=18 change_duration=18 startpos=0 endpos=0>
                    <span class='time_info' id='control4_timeinfo'></span>
                    <div class='video_left_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                    <div class='video_right_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                </div>
            </div>
            <div class='take_row'id='take5_area'>
                <h2>TAKE5</h2>
                <div class='videotake_control' dataset-take=5 id='control5'original_duration=9 change_duration=9 startpos=0 endpos=0>
                    <span class='time_info' id='control5_timeinfo'></span>
                    <div class='video_left_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                    <div class='video_right_duration_control'>
                        <img src='resource/arrow.png'/>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <hr/><hr/>

    <div class='editing_area'>
        <h3>지정된 최종출력된 비디오들 병합&처리(사이사이 트랜지션)</h3>
        <div class='video_upload_area' id='video_upload_area_final'>
            <div id='take1_video_' class='upload_video_element plus'>
                <label>TAKE1</label>
                <video id='upload_video0_' src='' width=320 height=180 controls></video>
            </div>
            <div id='take2_video_'class='upload_video_element plus'>
                <label>TAKE2</label>
                <video id='upload_video1_' src='' width=320 height=180 controls></video>
            </div>
            <div id='take3_video_'class='upload_video_element plus'>
                <label>TAKE3</label>
                <video id='upload_video2_' src='' width=320 height=180 controls></video>
            </div>
            <div id='take4_video_'class='upload_video_element plus'>
                <label>TAKE4</label>
                <video id='upload_video3_' src='' width=320 height=180 controls></video>
            </div>
            <div id='take5_video_'class='upload_video_element plus'>
                <label>TAKE5</label>
                <video id='upload_video4_' src='' width=320 height=180 controls></video>
            </div>
        </div>
    </div>
</div>
<script>
    var oReq=new XMLHttpRequest();
    oReq.open('GET','https://clllap.s3.ap-northeast-2.amazonaws.com/clllap/EZRrgAqzfAFYYu1CcNkF_encoded2.mp4',true);
    //oReq.responseType='arraybuffer';
    oReq.responseType='blob';//blobs? file blob , arraybuffer  blob->arraybfurrerssss  blob:url blob:url filess blob.arraybuffer();arraybuffersss
    //arraybuffer blob->arraybuffer:innerIntarray->uint8array converstion
    oReq.onreadystatechange=async function(oEvent){
        console.log('xmlhttpRequest readystathe sttuss:',oReq.readyState);

        if(oReq.readyState===oReq.DONE){
            if(oReq.status===200){
                var ressss=oReq.response;
                console.log('resssss :',ressss);
                console.log('get array bufferss!!:',new Blob([oReq.response],{type:'video/mp4'}));
                var blob= new Blob([oReq.response],{type:'video/mp4'});
                var url= URL.createObjectURL(blob);
                console.dir(blob);
                console.log(url);
                //.videoTestoutput.src= url;

                sampleVideoData=blob;

                //let tests=new Uint8Array(blob);
                var buffer = await blob.arrayBuffer();
                console.log('blob to buffer1!!!:',buffer);
                console.dir(buffer);

                sampleVideoData=buffer;
                console.dir(new Uint8Array(buffer));
                if(buffer){
                    sampleVideoData=new Uint8Array(buffer);
                    console.log('get new8intarray buffer to unit8arraysss:',sampleVideoData);
                }  
            }
        }                        
    }
    oReq.send();

    //fmpegwasm inital
    const {createFFmpeg,fetchFile} = FFmpeg;
    const ffmpeg=createFFmpeg({log:true});

    //비디오편집 관련 스크립트(테이크별 전체 프레임 저장하기위한)
    let original_to_videoEdit = document.getElementById('original_to_videoEdit');//원본 비디오를 자르기위한 관련된 부분

    let canvasinput_takevideo_wrap=document.getElementById('canvasinput_takevideo_wrap');
    for(let s=0; s<3000; s++){
        let canvasElement=document.createElement("CANVAS");
        canvasElement.id=`canvasinput_takevideo${s+1}`;//삼천개 가량 생성>>
        canvasinput_takevideo_wrap.appendChild(canvasElement);
    }

    //원본비디오 부분 제어 및 추출 관련 데이터처리>>
    function video_takecontrol_move_closure (){

        let move_target=null; let move_target_=null;
        let move_parentTarget=null;//무브오브젝트 자체를 클릭한 경우에는 move_parentTarget,mmove_target동일하게끔하고, 그게 아닌경우라면 다르게한다.
        let isdrag=false; let isdrag_=false;
        let move_object_pos={};  let move_object_pos_={};
        let time_grid_elements=document.getElementsByClassName('time_grid');

        //videoTake element 어떤것을 클릭시작하여 드래그 시작했는지 start origin관련 해당 클로저함수내부체에서 어떤 타깃을 클릭했었고, 그 특정타깃이 클릭해서 뗐는지 여부 파악.>>>
        function mousedown_module(event){
            event.preventDefault();

            move_target=event.target;

            console.log('드래그할 대상 move_tagets:',move_target,move_target.classList,move_target.className);

            if(move_target.className.indexOf('videotake_control')==-1){
                //좌우 리사이즈요소 관련 처리한경우
                console.log('videoTake_control요소가 아님!!:',move_target,event.target);
                /*if(move_target.className.indexOf('video_right_duration_control')!=-1 || move_target.className.indexOf('video_left_duration_control')!=-1){
                    console.log('video_left,right duraitoncontorls가 클릭이 된경우 인지된경우!');
                    move_target=move_target.parentElement;
                }*/
                move_target=event.target;
                move_parentTarget=move_target.parentElement;//부모요소 해당 좌우요소의 부모요소(element자체)
            }else{
                //비디오컨트롤 요소 자체를 처리하는경우(위치이동)
                console.log('videoTake_control요소임!!',move_target,event.target);
                move_target=event.target;
                move_parentTarget=move_target;
            }   
            isdrag=true;
        }
        //deprecated!..
        function mousedown_module_(event){
            event.preventDefault();

            move_target_ =event.target;

            console.log('드래그 대상 move_targsss:(mouwsedown_moudle)::',move_target_,move_target_.classList,move_target_.className);
            isdrag_=true;
        }
        //takerow요소에 거는 이벤트들>>>
        /*function mousemove_module(event){
            let current_target=event.target;
            //console.log("mousemove이벤트 발생 관련 객체:",move_target,event.target);

            if(isdrag && move_target.className.indexOf("videotake_control")!=-1){
                console.log('드래그중 상태::>>videotake_control요소 자체를 move액션 관련',isdrag,current_target,move_target);

                console.log('현재 마우스위치(clientX클라이언트 화면뷰포트 좌표기준::',event.clientX,event.clientY);//대상 개체 targetElement가 아닌 takeROW area에서의 x좌표값 (offset좌표임)구해서 그 위치값에 대해서 기억하고있다가 그 위치로 mouseup시에 이동시킨다.
                move_object_pos['x']=event.clientX;
                move_object_pos['y']=event.clientY;
            }else if(isdrag && (move_target.className.indexOf("video_left_duration_control")!=-1)){
                console.log("드래그 중 상태::video left,right size duration change move액션관련",isdrag,current_target,move_target);

                console.log('현재 마우스위치(clientX 클라이언트 화면뷰포트 좌표기준:',event.clientX,event.clientY);
                move_object_pos['x'] = event.clientX;
                move_object_pos['y'] = event.clientY;
            }
        }*/
        //deprecated..!
        function mouseup_module_(event){
            let current_target=event.target;
            console.log('mouseup이벤트 발생 관련 객체:',current_target,event.target,isdrag_);

            if(isdrag_){
                move_object_pos_['x']= event.clientX;
                move_object_pos_['y']= event.clientY;

                console.log('mouseup이벤트 발생 move당시때의 offset위치정보값:',move_object_pos_,move_target_);

                if(move_target_.className.indexOf('videotake_control_')!=-1){
                    console.log('videotakeControl요소 자체를 이동시키려고하는 경우:',move_target_);
                    let adapt_x= move_object_pos_['x'];//해당 x위치로 이동시킨다.
                    let distance_array=[];
                    for(let t=0; t<time_grid_elements.length; t++){
                        console.log('mouseup당시때의 adapt_x좌표 offsetX,clientX와 가장 가까운 대상 찾기');
                        let item=time_grid_elements[t];
                        let offsetX=item.offsetLeft;
                        console.log('item offisetX, adapt_x:',offsetX, adapt_x);

                        let distance= Math.abs(adapt_x-offsetX);
                        distance_array.push({
                            index : t+1,
                            object: time_grid_elements[t],
                            value : distance
                        });
                    }
                    console.log('==>>>매 확인된 distance값::',distance_array);
                    //가장 작은값 순으로 해서 정렬 가장 첫요소 찾기
                    let sort_result = distance_array.sort(function(a,b){
                        let left = parseInt(a.value);
                        let right = parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_array:',distance_array);
                    let adapt_final_target=distance_array[0].object;
                    console.log('대상 타깃 leftoffsetX시작위치index값',distance_array[0].index);
                    let adapt_final_targetindex=distance_array[0].index;
                    //move_target.style.left =adapt_final_target.offsetLeft+'px';
                    move_target_.style.left = 3.333*(adapt_final_targetindex -1 )+'%';

                    move_target_.setAttribute('startpos',adapt_final_targetindex -1 );
                    let change_duration = parseInt(move_target_.getAttribute('change_duration'));//변화적용된 최종길이값(초값) startpos = x + durationvalue
                    let end_pos=(adapt_final_targetindex -1) + change_duration;
                    move_target.setAttribute('endpos',end_pos);

                    let id_val=move_parentTarget.id.replace('control_','');

                }
            }
            isdrag_=false;
        }
        function mouseup_module(event){
            let current_target=event.target;
            console.log('mouseup이벤트 발생 관련 객체:',current_target,event.target);

            if(isdrag){
                move_object_pos['x']= event.clientX;
                move_object_pos['y']= event.clientY;

                console.log('mouseup이벤트 발생 move당시때의 offset위치정보값:',move_object_pos,move_target);

                if(move_target.className.indexOf('videotake_control')!=-1){
                    console.log('videotakeControl요소 자체를 이동시키려고하는 경우:',move_target);
                    let adapt_x= move_object_pos['x'];//해당 x위치로 이동시킨다.
                    let distance_array=[];
                    for(let t=0; t<time_grid_elements.length; t++){
                        console.log('mouseup당시때의 adapt_x좌표 offsetX,clientX와 가장 가까운 대상 찾기');
                        let item=time_grid_elements[t];
                        let offsetX=item.offsetLeft;
                        console.log('item offisetX, adapt_x:',offsetX, adapt_x);

                        let distance= Math.abs(adapt_x-offsetX);
                        distance_array.push({
                            index : t+1,
                            object: time_grid_elements[t],
                            value : distance
                        });
                    }
                    console.log('==>>>매 확인된 distance값::',distance_array);
                    //가장 작은값 순으로 해서 정렬 가장 첫요소 찾기
                    let sort_result = distance_array.sort(function(a,b){
                        let left = parseInt(a.value);
                        let right = parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_array:',distance_array);
                    let adapt_final_target=distance_array[0].object;
                    console.log('대상 타깃 leftoffsetX시작위치index값',distance_array[0].index);
                    let adapt_final_targetindex=distance_array[0].index;
                    //move_target.style.left =adapt_final_target.offsetLeft+'px';
                    move_target.style.left = 3.333*(adapt_final_targetindex -1 )+'%';

                    move_target.setAttribute('startpos',adapt_final_targetindex -1 );
                    let change_duration = parseInt(move_target.getAttribute('change_duration'));//변화적용된 최종길이값(초값) startpos = x + durationvalue
                    let end_pos=(adapt_final_targetindex -1) + change_duration;
                    move_target.setAttribute('endpos',end_pos);

                    let id_val=move_parentTarget.id.replace('control','');
                    let control_timeinfo = document.getElementById(`control${id_val}_timeinfo`);
                    let string_make = `DURATION = ${change_duration}, STARTPOS = ${adapt_final_targetindex-1}, ENDPOS = ${end_pos}`;
                    control_timeinfo.innerHTML = string_make;

                    //visual video target elements visible expand view controls..
                    let visual_video_take_element=document.getElementById(`take${id_val}_video`);
                    let visual_video_take_element_rangechilds=visual_video_take_element.children;

                    let make_range_string=[];
                    for(let s=adapt_final_targetindex; s<=end_pos; s++){
                        make_range_string.push(s);
                    }
                    console.log('현재 videocontrol moveaction에 따른 시간범위 make_range_stringss:',make_range_string);
                    for(let i=0; i<visual_video_take_element_rangechilds.length; i++){
                        if(visual_video_take_element_rangechilds[i].className.indexOf('visible_range_cut')!=-1){
                            let target=visual_video_take_element_rangechilds[i];
                            let target_timeindex=parseInt(target.getAttribute('time_index'));
                            console.log('==>>대상타깃targetss:',target,target_timeindex);
                            console.log('target hwatsss존재하나??:',target,make_range_string.includes(target_timeindex), i);
                            if( make_range_string.includes(target_timeindex)){
                                target.style.backgroundColor='rgba(0,0,0,0.0)';
                            }else{
                                target.style.backgroundColor='rgba(0,0,0,0.9)';
                            }
                        }
                    }
                }else if(move_target.className.indexOf("video_left_duration_control")!=-1){
                    //이동연산 + 크기 resize연산 둘다 진행>>
                    console.log('video_left_duration_control 요소를 mousedown했다가 drag하여 mouseup한경우:',move_target,move_parentTarget);
                    let adapt_x= move_object_pos['x'];
                    let distance_array=[];
                    let distance_array2=[];
                    let mother_object_offsetrightX = parseFloat(move_parentTarget.offsetLeft) + parseFloat(window.getComputedStyle(move_parentTarget,null)['width']);

                    for(let t=0; t<time_grid_elements.length; t++){
                        console.log('mouseup당시때의 adapt_x좌표 offsetX,clientX와 가장 가까운 대상찾기 timegrid위치대상찾기');
                        console.log('mouseup당시때의 또한 대상타깃의 mother moveParentElement의 rightoffsetX위치값이 어떤 인댁스상에 있었는지,adaptx좌표는 또한');
                        let item=time_grid_elements[t];
                        let offsetX=item.offsetLeft;
                        console.log('item offsetX,adapt_x,motherobject_offsetrightX:',offsetX,adapt_x,mother_object_offsetrightX);

                        let distance= Math.abs(adapt_x - offsetX);
                        distance_array.push({
                            index : t+1,
                            object: time_grid_elements[t],
                            value : distance
                        });
                        let distance2 = Math.abs(mother_object_offsetrightX - offsetX);
                        distance_array2.push({
                            index : t+1,
                            object:time_grid_elements[t],
                            value: distance2
                        });
                    }
                    console.log('==>>>매 확인된 distance값::',distance_array);
                    console.log('==>>>매 확인된 distance2값::',distance_array2);
                    //가장 작은값 순으로 해서 정렬 가장 첫요소 찾기
                    let sort_result = distance_array.sort(function(a,b){
                        let left =parseInt(a.value);
                        let right= parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_arrayss:',distance_array);
                    let sort_result2 = distance_array2.sort(function(a,b){
                        let left =parseInt(a.value);
                        let right= parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_arrayss:',distance_array2);
                    
                    //1.최종 관련 마우스mouseup된 위치값과의 격차가 가장 적은 timegrid offsetLeft위치 object를 찾는다.그리고 그 위치로 moveTarget이동시킴.
                    let adapt_final_target=distance_array[0].object;
                    let adapt_final_targetindex=distance_array[0].index;
                    //move_parentTarget.style.left = adapt_final_target.offsetLeft + 'px';
                    move_parentTarget.style.left = (3.333 * (adapt_final_targetindex-1))+'%';
                    //2. mouseup이벤트 발생시점때에 motherElement의 offsetRight xleft값위치인접한 위치시작인댁스index-1 - adaptfinaltARGET INDEX값과의 차이값의 곧 IDNEX차이격차값이 각 인댁스는 일초값이고 이값 N% * s값 만큼의 폭을 가진다%폭으로 처리한다(반응형고려) 또한 몇초duration인지도 추적가능함.
                    
                    let adapt_final_posx_index=distance_array[0].index;//해당 이동할 위치와 moveMother object rightPosx와의 격차값은 새로 반영width크기이다.
                    let mother_object_offsetrightX_index= distance_array2[0].index;
                    console.log('adapt_final_posxIndex,mother_object_fofsetrightXindex:',adapt_final_posx_index,mother_object_offsetrightX_index);
                    let adapt_width_duration = mother_object_offsetrightX_index - adapt_final_posx_index;
                    console.log('적용 duration초 상수값::',adapt_width_duration);

                    if(adapt_width_duration >= 0 && adapt_width_duration < 1){
                        alert('적용 duration이 1초는 되어야합니다.');
                        adapt_width_duration = 1;

                    }else if(adapt_width_duration > move_parentTarget.getAttribute('original_duration')){
                        alert('영상 고유의 duration값보다 더 크게 지정하려고 했던경우.');
                        adapt_width_duration = move_parentTarget.getAttribute('original_duration');

                    }else if(adapt_width_duration < 0){
                        alert('적용 duration이 유효하지 않습니다!!');
                        adapt_width_duration = 1;
                    }
                    move_parentTarget.setAttribute('change_duration',adapt_width_duration);
                    move_parentTarget.style.width = parseFloat( 3.333 * adapt_width_duration)+'%'; 

                    move_parentTarget.setAttribute('startpos',adapt_final_targetindex-1);
                    //변화 적용된 당시때의 change_duration값을 더해서 한다.
                    //let change_duration = parseInt(move_parentTarget.getAttribute('change_duration'));
                    let change_duration = adapt_width_duration;
                    let end_pos = (adapt_final_targetindex - 1) + change_duration;
                    move_parentTarget.setAttribute('endpos',end_pos);

                    let id_val=move_parentTarget.id.replace('control','');
                    let control_timeinfo = document.getElementById(`control${id_val}_timeinfo`);
                    let string_make = `DURATION = ${adapt_width_duration}, STARTPOS = ${adapt_final_targetindex-1}, ENDPOS = ${end_pos}`;
                    control_timeinfo.innerHTML = string_make;

                    //visual video target elements visible expand view controls..
                    let visual_video_take_element=document.getElementById(`take${id_val}_video`);
                    let visual_video_take_element_rangechilds=visual_video_take_element.children;

                    let make_range_string=[];
                    for(let s=adapt_final_targetindex; s<=end_pos; s++){
                        make_range_string.push(s);
                    }
                    console.log('현재 videocontrol resize_action에 따른 시간범위 make_range_stringss:',make_range_string,visual_video_take_element_rangechilds);
                    for(let i=0; i<visual_video_take_element_rangechilds.length; i++){
                        if(visual_video_take_element_rangechilds[i].className.indexOf('visible_range_cut')!=-1){
                            let target=visual_video_take_element_rangechilds[i];
                            let target_timeindex=parseInt(target.getAttribute('time_index'));
                            console.log('target,targetindexxx::',target,target_timeindex);
                            console.log('target hwatsss존재하나??:',target,target.getAttribute('time_index'),make_range_string.includes(target_timeindex), i);
                            if( make_range_string.includes(target_timeindex)){
                                target.style.backgroundColor='rgba(0,0,0,0.0)';
                            }else{
                                target.style.backgroundColor='rgba(0,0,0,0.9)';
                            }
                        }
                    }

                    //크기변환 이벤트시에만 아래의 비디오 및 관련요소들 크기 변환한다>>
                    let original_duration = parseInt(move_parentTarget.getAttribute('original_duration'));
                    let target_video__content = document.getElementById(`take${id_val}_video_`);
                    let adapt_width_percent = (20 * parseFloat(adapt_width_duration / original_duration)).toFixed(3);
                    target_video__content.style.width = adapt_width_percent +'%';

                    /*let after_controlcontent = document.getElementById(`control${id_val}_final`);
                    after_controlcontent.setAttribute('change_duration',adapt_width_duration);
                    after_controlcontent.style.width = parseFloat(3.333 * adapt_width_duration)+'%';*/

                }else if(move_target.className.indexOf("video_right_duration_control")!=-1){
                    //크기 resize연산 둘다 진행>>
                    console.log('video_right_duration_control 요소를 mousedown했다가 drag하여 mouseup한경우:',move_target,move_parentTarget);
                    let adapt_x= move_object_pos['x'];
                    let distance_array=[];
                    let distance_array2=[];
                    let mother_object_offsetleftX = parseFloat(move_parentTarget.offsetLeft);

                    for(let t=0; t<time_grid_elements.length; t++){
                        console.log('mouseup당시때의 adapt_x좌표 offsetX,clientX와 가장 가까운 대상찾기 timegrid위치대상찾기');
                        console.log('mouseup당시때의 또한 대상타깃의 mother moveParentElement의 rightoffsetX위치값이 어떤 인댁스상에 있었는지,adaptx좌표는 또한');
                        let item=time_grid_elements[t];
                        let offsetX=item.offsetLeft;
                        console.log('item offsetX,adapt_x,motherobject_offsetrightX:',offsetX,adapt_x,mother_object_offsetleftX);

                        let distance= Math.abs(adapt_x - offsetX);
                        distance_array.push({
                            index : t+1,
                            object: time_grid_elements[t],
                            value : distance
                        });
                        let distance2 = Math.abs(mother_object_offsetleftX - offsetX);
                        distance_array2.push({
                            index : t+1,
                            object:time_grid_elements[t],
                            value: distance2
                        });
                    }
                    console.log('==>>>매 확인된 distance값::',distance_array);
                    console.log('==>>>매 확인된 distance2값::',distance_array2);
                    //가장 작은값 순으로 해서 정렬 가장 첫요소 찾기
                    let sort_result = distance_array.sort(function(a,b){
                        let left =parseInt(a.value);
                        let right= parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_arrayss:',distance_array);
                    let sort_result2 = distance_array2.sort(function(a,b){
                        let left =parseInt(a.value);
                        let right= parseInt(b.value);

                        if(left < right){
                            return -1;
                        }
                        if(left > right){
                            return 1;
                        }
                        return 0;
                    });
                    console.log('정렬처리후 distance_arrayss:',distance_array2);
                    
                    //1.최종 관련 마우스mouseup된 위치값과의 격차가 가장 적은 timegrid offsetLeft위치 object를 찾는다.그리고 그 위치로 moveTarget이동시킴.
                    let adapt_final_target=distance_array[0].object;
                    let adapt_final_targetindex=distance_array[0].index;               
                    
                    let adapt_final_posx_index=distance_array[0].index;//해당 이동할 위치와 moveMother object rightPosx와의 격차값은 새로 반영width크기이다.
                    let mother_object_offsetleftX_index= distance_array2[0].index;
                    console.log('adapt_final_posxIndex,mother_object_fofsetrightXindex:',adapt_final_posx_index,mother_object_offsetleftX_index);
                    let adapt_width_duration = adapt_final_posx_index - mother_object_offsetleftX_index;
                    console.log('적용 duration초 상수값::',adapt_width_duration);

                    if(adapt_width_duration >= 0 && adapt_width_duration < 1){
                        alert('적용 duration이 1초는 되어야합니다.');
                        adapt_width_duration = 1;

                    }else if(adapt_width_duration > move_parentTarget.getAttribute('original_duration')){
                        alert('영상 고유의 duration값보다 더 크게 지정하려고 했던경우.');
                        adapt_width_duration = move_parentTarget.getAttribute('original_duration');

                    }else if(adapt_width_duration < 0){
                        alert('적용 duration이 유효하지 않습니다!!');
                        adapt_width_duration = 1;
                    }
                    adapt_width_duration = parseInt(adapt_width_duration);

                    move_parentTarget.setAttribute('change_duration',adapt_width_duration);
                    move_parentTarget.style.width = parseFloat( 3.333 * adapt_width_duration)+'%'; 
                
                    let start_pos = parseInt(move_parentTarget.getAttribute('startpos'));
                    let end_pos = start_pos + adapt_width_duration;
                    move_parentTarget.setAttribute('endpos',end_pos);

                    let id_val =move_parentTarget.id.replace('control','');
                    let control_timeinfo = document.getElementById(`control${id_val}_timeinfo`);
                    let string_make = `DURATION = ${adapt_width_duration} , STARTPOS = ${start_pos} , ENDPOS = ${end_pos}`;
                    control_timeinfo.innerHTML = string_make; 
                    

                    //visual video target elements visible expand view controls..
                    let visual_video_take_element=document.getElementById(`take${id_val}_video`);
                    let visual_video_take_element_rangechilds=visual_video_take_element.children;

                    let make_range_string=[];
                    for(let s=(start_pos+1); s<=end_pos; s++){
                        make_range_string.push(s);
                    }
                    console.log('현재 videocontrol resize_action에 따른 시간범위 make_range_stringss:',make_range_string,visual_video_take_element_rangechilds);
                    for(let i=0; i<visual_video_take_element_rangechilds.length; i++){
                        if(visual_video_take_element_rangechilds[i].className.indexOf('visible_range_cut')!=-1){
                            let target=visual_video_take_element_rangechilds[i];
                            let target_timeindex=parseInt(target.getAttribute('time_index'));
                            console.log('target,target timeindex:',target,target_timeindex);
                            console.log('target hwatsss존재하나??:',target,target.getAttribute('time_index'),make_range_string.includes(target_timeindex), i);
                            if( make_range_string.includes(target_timeindex)){
                                target.style.backgroundColor='rgba(0,0,0,0.0)';
                            }else{
                                target.style.backgroundColor='rgba(0,0,0,0.9)';
                            }
                        }
                    }

                    //크기변환 이벤트시에만 아래의 비디오 및 관련요소들의 크기를 변환한다.
                    let original_duration = parseInt(move_parentTarget.getAttribute('original_duration'));
                    let target_video__content = document.getElementById(`take${id_val}_video_`);
                    let adapt_width_percent= (20 * parseFloat(adapt_width_duration / original_duration)).toFixed(3);
                    target_video__content.style.width = adapt_width_percent +'%';

                    /*let after_controlcontent = document.getElementById(`control${id_val}_final`);
                    after_controlcontent.setAttribute('change_duration',adapt_width_duration);
                    after_controlcontent.style.width = parseFloat(3.333 * adapt_width_duration)+'%';*/
                }
            }
            isdrag=false;
        }
        return [mousedown_module,mouseup_module,mousedown_module_,mouseup_module_];
    }
    var return_set = video_takecontrol_move_closure();
    var video_takecontrol_mousedown = return_set[0];
    var video_takecontrol_mouseup = return_set[1];
    var video_takecontrol_mousedown_ = return_set[2];
    var video_takecontrol_mouseup_ = return_set[3];

    console.log('관련 타깃 대상함수::',video_takecontrol_mousedown,video_takecontrol_mouseup,video_takecontrol_mousedown_,video_takecontrol_mouseup_);

    //트랙자체를 이동시키는 관련 이벤트.
    let video_track_elements=document.getElementsByClassName('videotake_control');
    //각 테이크별 row영역 해당 영역에 mousemove,up관련 핸들러 등록(이동관련)
    let take_row_area=document.getElementsByClassName('take_row');
    //각 트랙의 left,right 크기조정bar관련 사이즈조절관련 핸들러
    let video_left_duration_control = document.getElementsByClassName('video_left_duration_control');
    let video_right_duration_control = document.getElementsByClassName("video_right_duration_control");

    let video_track_elements_=document.getElementsByClassName('videotake_control_');
    let take_row_areas_=document.getElementsByClassName('take_row_');


    //video_track_elements(mousedown이동 핸들러mousedown)
    for(let j=0; j<video_track_elements.length; j++){
        let item=video_track_elements[j];
        item.addEventListener('mousedown',video_takecontrol_mousedown,false);   
    }
    /*for(let j=0; j<video_track_elements_.length; j++){
        let item=video_track_elements_[j];
        item.addEventListener('mousedown',video_takecontrol_mousedown_,false);
    }*/
    for(let j=0; j<take_row_area.length; j++){
        let item=take_row_area[j];
        item.addEventListener('mouseup',video_takecontrol_mouseup,false);
    }
    /*for(let j=0; j<take_row_areas_.length; j++){
        let item=take_row_areas_[j];
        item.addEventListener('mouseup',video_takecontrol_mouseup_,false);
    }*/

    //각 비디오controlbar의 보여질 초값 duration지정(자르기,늘리기관련 액션, 자르기의 경우 최소 1초이상의 값을 가져야만하며, 늘리기의 경우 원래의 타고난 duration길이이하여야만한다.)
    for(let s=0; s<video_left_duration_control.length; s++){
        let item=video_left_duration_control[s];
        let item2=video_right_duration_control[s];
        item.addEventListener('mousedown',video_takecontrol_mousedown,false);
        item2.addEventListener('mousedown',video_takecontrol_mousedown,false);
    }
    //비디오 편집 관련 스크립트ends...


    //트랜지션,필터,오버레이 관련starts...(opencv.js with..)
    //let video=document.getElementById('video');

    let test_extract=document.getElementById('test_extract');

    let canvasinput1=document.getElementById('canvasinput1');
    let canvasinput2=document.getElementById('canvasinput2');
    let context1=canvasinput1.getContext('2d');

    let canvasoutput1=document.getElementById('canvasOutput');
    let canvasoutput2=document.getElementById('canvasOutput2');
    let canvasoutput3=document.getElementById('canvasOutput3');
    let canvasoutput4=document.getElementById('canvasOutput4');
    let canvasoutput5=document.getElementById('canvasOutput5');
    let canvasoutput6=document.getElementById('canvasOutput6');
    let canvasoutput7=document.getElementById('canvasOutput7');
    let canvasoutput8=document.getElementById('canvasOutput8');

    let output_video_element= document.getElementById('output_video_element');

    //오버레이관련
    let testvideo2=document.getElementById('testvideo2');
    let overlay1=document.getElementById('overlay1');
    let overlay2=document.getElementById('overlay2');
    let overlay3=document.getElementById('overlay3');
    let overlay4=document.getElementById('overlay4');
    let overlay5=document.getElementById('overlay5');
    let overlay6=document.getElementById('overlay6');
    let overlay7=document.getElementById('overlay7');
    let overlay8=document.getElementById('overlay8');
    let overlay9=document.getElementById('overlay9');
    let overlay10=document.getElementById('overlay10');
    let canvasinput00=document.getElementById('canvasinput00');
    let canvasinput01=document.getElementById('canvasinput01');
    let canvasoutput00=document.getElementById("canvasoutput00");

    //let overlay_origin_src;//참조하는 형태로 한다고 해도 imread로 생성된 mat요소는 메모리상에서 할당(추가)되는것이기에 이걸 따로 해제가 필요함.
    //let overlay_effect_src;
    let origincap, overlay_cap;

    //let src;
    //let dst;
    //let cap;
    //var target_src;//필터 효과부여 관련
    //var overlay_src;//오버레이효과부여 관련 부여할 원본대상프레임
    var process_possible=false;

    /*function init_cv(){
        
        let src00 = new cv.Mat();
        src00 = cv.imread(test);
        console.log('src00:',src00);

        let src01 = new cv.Mat();
        src01 = cv.imread(test2);
        console.log('src01:',src01);
    }
    */

    //var target_src=new cv.Mat(720,1280,cv.CV_8UC4);
    
    //let overlay_dst;
    //let tmp_image;


    //opencv.js등 이펙트 효과 적용함수.
    //function image_transition_overlay_filterEffect_front(upload_count,upload_list,request_id, takeper_distinctfilename_data,takevideoper_avgframerate_array){
    function image_transition_overlay_filterEffect_front(event){  
        let upload_count=parseInt(event.target.getAttribute('loop_count'));
        let request_id=event.target.getAttribute('request_id');

        //트랜지션 처리관련
        let video_between_transition_startendArea=document.getElementById('video_between_transition_startendArea');
        let between_count=parseInt(video_between_transition_startendArea.children.length / 2);

        var formdata=new FormData();

        formdata.append('upload_count',upload_count);
        //formdata.append('upload_list',upload_list);

        for(let between=0; between<between_count; between++){
            let between_image_start=document.getElementById(`between_${between+1}_start`);
            let between_image_end = document.getElementById(`between_${between+1}_end`);
            
            /*switch((between+1)){
                case 1:
                    between_image_start = between_image_start1_g;
                    between_image_end = between_image_end1_g;
                break;
                case 2:
                    between_image_start = between_image_start2_g;
                    between_image_end = between_image_end2_g;
                break;
                case 3:
                    between_image_start = between_image_start3_g;
                    between_image_end = between_image_end3_g;
                break;
                case 4:
                    between_image_start = between_image_start4_g;
                    between_image_end = between_image_end4_g;
                break;
            }*/

            let alpha=1;let beta; 

            console.log('관련 타깃대상요소 별 전환>:',between_image_start,between_image_end);
            let between_start_s=cv.imread(between_image_start);
            let between_end_s=cv.imread(between_image_end);
            console.log('====>>각 사이장면between별 read값::',between_start_s,between_end_s);
            console.log('===>>트랜지션 처리::requestid:',request_id);
            
            for(let tran=0; tran<52; tran++){
                //장면별전환시에 52장 이미지를 초당 26개씩보여주는 26fps로 일단 처리>>(2초간처리) 52장의 변환이미지들을 처리하고 그것들을 2초의 장면 비디오로 처리한다.
                let blend_dst = new cv.Mat();
                let src1 = new cv.Mat(); let src2= new cv.Mat();//메모리해제바로 해줘야한다.

                //transition관련 처리 starts...OPENCV.js
                console.log('->>>각 장면 변환별 참조 이미지start~end:',between_image_start,between_image_end);
                //src1 = cv.imread(between_image_start);
                //src2 = cv.imread(between_image_end);
                src1= between_start_s.clone();
                src2 =between_end_s.clone();

                console.log('src1:',src1);
                console.log('src2:',src2);
                alpha -= (1/52); beta=1 - alpha;
                alpha = parseFloat(alpha.toFixed(2));
                beta = parseFloat(beta.toFixed(2));
                alpha = alpha <=0?0:alpha;
                beta = beta>=1?1:beta;
                console.log('alpha and betass:',alpha,beta);

                cv.addWeighted(src1,alpha,src2,beta,0.0,blend_dst,-1);
                let target_element=document.getElementById('canvasinput1-'+((52*(between))+(tran+1)));

                console.log('targetelemtensss:',target_element);
                cv.imshow(target_element, blend_dst);
                //transition관련 처리 ends...

                let data_url = target_element.toDataURL();//image urlsss
                console.log('get data urlsss:',data_url);

                let bstr= atob(data_url.split(",")[1]);
                let n = bstr.length;
                let u8arr = new Uint8Array(n);

                while(n--){
                    u8arr[n] = bstr.charCodeAt(n);
                }
                var file=new File([u8arr],`${request_id}_blend_transitionImg_between${between+1}_${(tran+1)}.png`);

                console.log('filesss:',file);
                formdata.append(`between${between+1}_${tran+1}`,file);//file개체 betwen1_1,2,3,4,5,.... between2_1,2,3,4,.... 이런식으로 한다. upload_count 4이면 사이공간between3까지 있을것임..
                //let input_loca=document.createElement('input');
                //input_loca.setAttribute('type','hidden');
                //input_loca.setAttribute('name',);
                //input_loca.setAttribute('value',)
                src1.delete();src2.delete();blend_dst.delete();
            }
            between_start_s.delete();
            between_end_s.delete();//행별 관련 데이터 해제.
        }
        
        //필터링 관련 처리>>(테이크별 비디오:테이크별 이미지들의 총 업로드수)
        let take_video_imgpart_total=document.getElementById('take_video_imgpart_total');
        let take_count=take_video_imgpart_total.children.length;

        let takeper_noeffect_framerange=[];//테이크별 전체프레임이미지분할데이터들중에서 이펙트가 랜덤하게 적용된 반영구간들(index범위임..index는 프레임이미지의 번호임) 

        let canvas_index=0; let videotake_upload_imgcnt=0;
        let videotake_effectframes_uploadcnt=0;
        //console.log('===>>비디오 필터관련 처리',takevideoper_avgframerate_array);

        let target_canvas_element=document.getElementById(`canvasinput_effect1`);//filer write.

        let random_overlay_serveframes_frames=document.getElementById('random_overlay_serveframesArea').children;
        let xhr_local = new XMLHttpRequest;
        xhr_local.responseType='blob';
        let fileReader_local=new FileReader();

        let noeffect_index=0; let noeffect_cnt=0;
        let xhr_request=[];//noeffect적용관련한 xhr요청 반복문내에서의 요청request 루프처리를 위한구조.

        for(let t=0; t<take_video_imgpart_total.children.length; t++){
            //take_video_imgpart_total관련 childrenList 리스트>>.....
            //let takevideo_avgframerate=takevideoper_avgframerate_array[t];
            //console.log('비디오테이크별 avgframeRate::!!!',t+1,takevideo_avgframerate);

            let item_loca=take_video_imgpart_total.children[t];//해당 take의 모든 장면들 프레임들(이미지들 대부분 99%)중에서 26fps기준으로 했을시 1초랜덤구간을  테이크별로 2개씩 집합한다. 
            let takevideo_duration=item_loca.getAttribute('duration');//초값>>재생시간값>>... 7초라고한다면 1,2,3,4,5,6,7 값중 5초라고 한다면 1,2,3,4,5 중 두개선택한 랜덤선택한 두개값을 리턴. 1초라고한다면 1중에 두개선택 일만 두개나옴>>두개 이펙트 겹쳐서 같이 나옴.1,3나왔을시 0~1  2~3초 구간에 해당하는 인댁스 번호체 1~26  26*2+1~26*3길이만큼 나오게한다.구간 이미지 집합들에 대해서 효과적용한다>>

            //필터효과 지정될 랜덤구간index프레임범위지정startss
            let random_index= Math.floor(takevideo_duration*Math.random());//0~6.999999xx형태의 수 0~6내림수를 처리한다.
            random_index += 1;//1~7사이의수가 나오게한다.
            //console.log('take별 랜덤구간 초범위형상화:',t+1, random_index-1,random_index);

            let random_start=random_index-2<0?0:random_index-2;
            let random_end = random_index;//6  4~6 7 5~7  3 1~3  2 0~2  1 -1~1 0~1
            let take_effect_adapt_targets=[];

            let take_range_start = 26 *(random_start)+1;
            let take_range_end = 26 * (random_end);
            //필터 효과 지정될 랜덤구간index범위 프레임범위 지정ends....

            //오버레이 효과 지정될 랜덤구간index프레임범위 지정starts...
            let random_index2= Math.floor(takevideo_duration*Math.random());
            random_index2 += 1;//위의 필터지정구간과 겹칠수도있음.겹치면 필터지정대상체에 겹쳐서 추가로 효과적용하면됨!

            let random_start2= random_index2-2<0?0:random_index2-2;
            let random_end2 = random_index2;
            let take_overlay_adapt_targets=[];

            let take_range_start2= 26*(random_start2)+1;
            let take_range_end2= 26 *(random_end2);
            //오버레이효과 지정될 랜덤구간index프레임범위지정end

            let imgpart_children=item_loca.children;
            let takeper_totalframes_length= imgpart_children.length;//테이크별 총 프레임index개수 800개라고한다면 1~800인댁스를 갖고있고, 1~26프레임인댁스, 26~78(이팩트적용), 79~800이낻스 범위 등 1~26/79~800위치등등 두가지 갈래로   1~60프레임였다면 앞부분없고 

            //let takeper_noeffect_rangelocalstore=[];

            /*if(take_range_end == takeper_totalframes_length){
                for(let sss=1; sss<take_range_start; sss++){
                    takeper_noeffect_rangelocalstore.push(sss);
                }
            }else{
                //미적용 partA
                for(let sss=1; sss<take_range_start; sss++){
                    takeper_noeffect_rangelocalstore.push(sss);//1~60 프레임적용랜덤구간였다면 앞부분에선 하는게 없을것임  40~180프레임 적용였다면 1~39인댁스위치에 대해서 반영된다. 그 범위는 미적용범위라는 것이다.
                }
                //미적용 partB
                for(let fff=take_range_end+1; fff<=takeper_totalframes_length; fff++){
                    takeper_noeffect_rangelocalstore.push(fff);//프레임의 인댁스값을 의미합니다.>>>
                }
            }*/
            //전체 이미지 index조회>>>테이크별
            let overlay_index=0;

            for(let inner=0; inner<imgpart_children.length; inner++){
                let local_item=imgpart_children[inner];
                let local_item_index=parseInt(local_item.getAttribute('index'));

                let target_canvas_element_refer;//중첩되는 경우 참조할수있게끔..imread나,opencv등의 함수가 mat배열메모리를 생성하여 반환하는 형태로 알고있다. 이런것들을 메모리해제해줘야함.
                if(take_range_start <= local_item_index && local_item_index <= take_range_end){
                    take_effect_adapt_targets.push(local_item);

                    let target_src=new cv.Mat();//let effect_dst=new cv.Mat();
                    target_src = cv.imread(local_item);//원본대상 그 대상체 이미지>>읽는다.매번 바뀐다 배열이 매벉 4채널 rgba채널 mat정보로 매번 바뀐다.mat메모리공간 생성반환 처리후 해제필요.

                    let result;
                    console.log('now controls controsl filtersss status:',controls,controls.filter);
                    switch (controls.filter) {
                        case 'passThrough': result = passThrough(target_src); break;
                        case 'gray': result = gray(target_src); break;
                        case 'hsv': result = hsv(target_src); break;
                        case 'canny': result = canny(target_src); break;
                        case 'inRange': result = inRange(target_src); break;
                        case 'threshold': result = threshold(target_src); break;
                        case 'adaptiveThreshold': result = adaptiveThreshold(target_src); break;
                        case 'gaussianBlur': result = gaussianBlur(target_src); break;
                        case 'bilateralFilter': result = bilateralFilter(target_src); break;
                        case 'medianBlur': result = medianBlur(target_src); break;
                        case 'sobel': result = sobel(target_src); break;
                        case 'scharr': result = scharr(target_src); break;
                        case 'laplacian': result = laplacian(target_src); break;
                        case 'contours': result = contours(target_src); break;
                        case 'calcHist': result = calcHist(target_src); break;
                        case 'equalizeHist': result = equalizeHist(target_src); break;
                        case 'backprojection': result = backprojection(target_src); break;
                        case 'erosion': result = erosion(target_src); break;
                        case 'dilation': result = dilation(target_src); break;
                        case 'morphology': result = morphology(target_src); break;
                        default: result = passThrough(target_src);
                    }
                    //target_src는 밖에서 생성하고 안에 넣어지면 안에서 삭제처리됨(메모리free해제), 그대로 내보내는경우 result참조변수에 의해서 제거처리. 안에서 삭제처리되고,result로 배출되는 dstc형태의 내부 목적mat개체는 외부에서 result.delete()로 메모리해제.

                    //hsv효과
                    /*cv.cvtColor(target_src,effect_dst,cv.COLOR_RGBA2RGB);
                    cv.cvtColor(effect_dst,effect_dst,cv.COLOR_RGB2HSV);*/
                    //let target_canvas_element=document.getElementById(`canvasinput_effect${canvas_index+1}`);
                    console.log('필터]]::적용 관련 타깃::',target_canvas_element);
                    target_canvas_element_refer=target_canvas_element;
                    /*let kernel = cv.Mat.ones(4,4,cv.CV_8U);
                    let color=new cv.Scalar();
                    cv.erode(target_src,effect_dst,kernel, {x:-1,y:-1},1,1,color);
                    kernel.delete();*/
                    
                    cv.imshow(target_canvas_element,result);//이펙트 적용된 것 mat vector 관련 대상 캔버스대상체에 적용한다imshow한다>>

                    let data_url = target_canvas_element.toDataURL();//바로 적용된 연산결과mat결과물 이미지데이터바로 적용가능한듯하고->그 적용된imshow대상체(canvas imshow대상체) url정보를 가져온다.
                    let bstr=atob(data_url.split(",")[1]);
                    let n =bstr.length;
                    let u8arr = new Uint8Array(n);

                    while(n--){
                        u8arr[n] = bstr.charCodeAt(n);
                    }
                    var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                    console.log('process filess:',file);
                    //target_src.delete();//effect_dst.delete();
                    result.delete();

                    formdata.append(`takevideo${t+1}_${inner+1}`,file);

                    canvas_index++;
                }               
                
                if(take_range_start2 <= local_item_index && local_item_index <= take_range_end2){
                    take_overlay_adapt_targets.push(local_item);
                    //오버레이효과를 중첩반영합니다.(겹치는경우라고한다면) 오버레이가 반영되는 구간26회수 만큼만. index증가 및 처리.

                    if(take_range_start <= local_item_index && local_item_index <= take_range_end){
                        //해당 오버레이에 해당했던 범위가 filter범위에도 해당했었던것이라면!(두개가 중첩된경우):참고로 일단 두 효과모두 적용되는 fps값,적용시간값 등은 모두 같은 통일된 형태로 처리진행>>라고 가정>
                        console.log('오버레이적용범위가 필터적용index범위와 일치했던경우 겹치는 연산진행!!중첩 이펙트효과진행::');
                        console.log('참조할 targetcanvaselement refer:',target_canvas_element_refer);
                        //let target_canvas_element=document.getElementById(`canvasinput_effect${canvas_index+1}`);//기존 이펙트필터가 적용이 된 캔버스요소를 덮어씌우는 연산이 필요합니다.

                        let target_overlay_frame=random_overlay_serveframes_frames[overlay_index];
                        let src_overlay=new cv.Mat();
                        src_overlay=cv.imread(target_overlay_frame);
                        let tmp_image=new cv.Mat();
                        tmp_image=cv.imread(target_canvas_element_refer);//Mat를 읽어옵니다.

                        let overlay_dst=new cv.Mat();//overlay저장할 대상mat객체.

                        cv.addWeighted(tmp_image,1,src_overlay,0.72,0.0,overlay_dst,-1);
                        cv.imshow(canvasoutput00,overlay_dst);

                        let data_url=canvasoutput00.toDataURL();
                        let bstr=atob(data_url.split(",")[1]);
                        let n =bstr.length;
                        let u8arr = new Uint8Array(n);

                        while(n--){
                            u8arr[n] = bstr.charCodeAt(n);
                        }
                        var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                        console.log('<<중첩>>process filess:',file);
                        //target_src.delete();//effect_dst.delete();

                        //formdata.delete(`takevideo${t+1}_${inner+1}`);//기존 중첩효과를 반영하기위해 파일formdata처리되었던keyvalue data는 삭제하고 갱신등록한다.
                        //formdata.append(`takevideo${t+1}_${inner+1}`,file);
                        formdata.set(`takevideo${t+1}_${inner+1}`,file);

                        src_overlay.delete();tmp_image.delete();overlay_dst.delete();

                    }else{
                        let overlay_src=new cv.Mat();
                        overlay_src=cv.imread(local_item);//겹치지않았던경우만 원본을 읽어오기에 
                        //해당 오버레이의 범위가 filter범위와 겹치지 않은 형태라고한다면 index값,file등은 중첩겹치지않을것임!더 많은 데이터 전달됨(이펙트처리)
                        console.log('오버레이 적용범위가 필터적용index범위와 겹치지 않았던경우!!!!별도 독립적 효과진행만!원본프레임에 바로 진행>>');
                        let target_overlay_frame=random_overlay_serveframes_frames[overlay_index];
                        let src_overlay=new cv.Mat();
                        src_overlay=cv.imread(target_overlay_frame);

                        let overlay_dst=new cv.Mat();

                        cv.addWeighted(overlay_src,1,src_overlay,0.72,0.0,overlay_dst,-1);
                        cv.imshow(canvasoutput00,overlay_dst);

                        let data_url=canvasoutput00.toDataURL();
                        let bstr=atob(data_url.split(",")[1]);
                        let n =bstr.length;
                        let u8arr = new Uint8Array(n);

                        while(n--){
                            u8arr[n] = bstr.charCodeAt(n);
                        }
                        var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                        console.log('<<별도:overlay>>process filess:',file);
                        //target_src.delete();//effect_dst.delete();
                        
                        formdata.append(`takevideo${t+1}_${inner+1}`,file);

                        overlay_src.delete();src_overlay.delete();overlay_dst.delete();
                    }

                    overlay_index++;
                }

                if(!(take_range_start <= local_item_index && local_item_index <= take_range_end) &&  !(take_range_start2 <= local_item_index && local_item_index <= take_range_end2) ){
                    //오버레이효과도, 오버레이&필터 효과도, 모두 아닌 미적용 구간들.
                    //let target_src=new cv.Mat();
                    //target_src= cv.imread(local_item);//미적용된 원본 이미지 데이터배열자체 매트릭스

                    //let target_canvas_element=document.getElementById(`canvasinput_effect${canvas_index+1}`);
                   // console.log('==>>필터,오버레이 미적용 원본관련타깃:',target_canvas_element);
                    //cv.imshow(target_canvas_element,target_src);//canvas에 이미지 반영
                    /*noeffect_cnt++;
                    console.log('이펙트효과 미적용 구간!:',local_item,local_item_index,local_item.src);

                    let fileReader_localss=new FileReader();
                    (function(noeffect_index,inner){

                        xhr_request[noeffect_index] = new XMLHttpRequest();
                        xhr_request[noeffect_index].open("GET",local_item.src);
                        xhr_request[noeffect_index].responseType='blob';

                        xhr_request[noeffect_index].onload=function(){
                            let recoveredblob= xhr_request[noeffect_index].response;

                            fileReader_localss.onload = function(){
                                let blob_as_dataurl = fileReader_localss.result;
                                console.log('bloburl->blob->dataurl(base64)')
                                //let data_url= target_canvas_element.toDataURL();
                                let bstr=atob(blob_as_dataurl.split(',')[1]);
                                let n = bstr.length;
                                let u8arr=new Uint8Array(n);

                                while(n--){
                                    u8arr[n]=bstr.charCodeAt(n);
                                }
                                var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                                console.log('process filesss:',file,noeffect_index,inner);
                                //target_src.delete();

                                formdata.append(`takevideo${t+1}_${inner+1}`,file);

                                canvas_index++;
                                videotake_effectframes_uploadcnt++;
                            }
                            console.log('원본처리이미지 복구된 bloburl -> blob정보:',recoveredblob);
                            fileReader_localss.readAsDataURL(recoveredblob);
                        }
                        xhr_request[noeffect_index].send();
                    })(noeffect_index,inner);
                    /*let xhr_locals=new XMLHttpRequest();
                    let fileReader_localss=new FileReader();

                    xhr_locals.onload= function(){
                        let recoveredblob= xhr_locals.response;

                        fileReader_localss.onload = function(){
                            let blob_as_dataurl = fileReader_localss.result;
                            console.log('bloburl->blob->dataurl(base64)')
                            //let data_url= target_canvas_element.toDataURL();
                            let bstr=atob(blob_as_dataurl.split(',')[1]);
                            let n = bstr.length;
                            let u8arr=new Uint8Array(n);

                            while(n--){
                                u8arr[n]=bstr.charCodeAt(n);
                            }
                            var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                            console.log('process filesss:',file);
                            //target_src.delete();

                            formdata.append(`takevideo${t+1}_${inner+1}`,file);

                            canvas_index++;
                            videotake_effectframes_uploadcnt++;
                        }
                        console.log('원본처리이미지 복구된 bloburl -> blob정보:',recoveredblob);
                        fileReader_localss.readAsDataURL(recoveredblob);
                    }
                    xhr_locals.open('GET',local_item.src);//blob_url read opoen
                    xhr_locals.send();*/
                   
                    let target_src=new cv.Mat();
                    target_src= cv.imread(local_item);//미적용된 원본 이미지 데이터배열자체 매트릭스

                    cv.imshow(target_canvas_element,target_src);//canvas에 이미지 반영

                    let data_url=target_canvas_element.toDataURL();
                    let bstr=atob(data_url.split(",")[1]);
                    let n =bstr.length;
                    let u8arr = new Uint8Array(n);

                    while(n--){
                        u8arr[n] = bstr.charCodeAt(n);
                    }
                    var file=new File([u8arr],`${request_id}_takevideo${t+1}_partimg_process${inner+1}.png`);
                    console.log('<<별도:overlay>>process filess:',file);
                    //target_src.delete();//effect_dst.delete();
                    
                    formdata.append(`takevideo${t+1}_${inner+1}`,file);

                    target_src.delete();
                    
                    noeffect_index++;
                } 
                //오버레이와 or 필터효과에 속하지 않는 합집합 범위구합니다.
                console.log('===>filter적용범위구간:',take_range_start,take_range_end);
                console.log('===>>overlay적용범위구간:',take_range_start2,take_range_end2);
                /*if((!(take_range_start <= local_item_index && local_item_index <= take_range_end)) && (!(take_range_start2 <= local_item_index && local_item_index <= take_range_end2))){
                    console.log(local_item_index,'해당 index범위는 filter or overlay에 모두 속하지않는것을 만족하는 범위로써 미적용구간에 추가합니다.');
                    //takeper_noeffect_rangelocalstore.push(local_item_index);
                }*/

                videotake_upload_imgcnt++;
            }//테이크별 전체 이미지frame별 접근(이미지src)하여 적용구간엔 적용하여 파일로 저장하고,아닌구간은 따로 저장해둔다.(필터or오버레이 모두 포함되지않는구간)

            console.log('take별 랜덤구간 초범위형상화 filter,overlay:',t+1,take_range_start,take_range_end,take_range_start2,take_range_end2,takeper_totalframes_length);
           // takeper_noeffect_framerange.push(takeper_noeffect_rangelocalstore);//테이크별 이펙트 미적용(필터,오버레이모두)구간 저장>>
            //console.log('각 테이크별(원본전체)에서 특정 랜럼구간(일초)에 해당하는 타깃 파트 이미지들::',take_effect_adapt_targets,take_overlay_adapt_targets,videotake_upload_imgcnt);
        }

        //let secure_cnt=0;
        //let upload_standby=window.setInterval(function(){

            //console.log('===>비디오테이크 이펙트 적용,비적용 전체적 업로딩이미지들 모두 관련 데이터준비완료때에 실행!:',videotake_effectframes_uploadcnt,noeffect_cnt);
            //if(noeffect_cnt == videotake_effectframes_uploadcnt){
                //clearInterval(upload_standby);
                //console.log('===>비디오테이크 이펙트 적용,비적용 전체적 업로딩이미지들 모두 관련 데이터준비완료때에 실행!:',videotake_effectframes_uploadcnt,noeffect_cnt);

        formdata.append("request_id",request_id);//요청관련 이전historyid값>> transition start requestid 
        formdata.append('takeper_noeffect_framerange',JSON.stringify(takeper_noeffect_framerange));
        //formdata.append('takeper_distinctfilename_data',takeper_distinctfilename_data);//테이크별 처리되었었던 업로드되었었던 파일시스템상의 구별 파일명(요청id_파일고유id값_subpart_img_형태의 format구조형태) 이럴경우 요청별로 처리된 과정상의 distinctfilename추적 가능하다
        formdata.append('videotake_partimg_totalcnt',videotake_upload_imgcnt);
        //formdata.append('takevideoper_avgframerate_array',takevideoper_avgframerate_array);//테이크별 처리되었던 평균frameratess....
        $.ajax({
            //url:'/upload_ver',
            url:'/upload_effectProcess2',
            //url:'/upload_ver_another',
            processData:false,
            contentType:false,
            data:formdata,
            type:"POST",
            error:function(jqxHR,textStatus,errorThrown){

            },
            beforeSend:function(){
                console.log('ajax startsss');
                $('#loading-progress')[0].style.display='flex';
            },
            complete:function(){
                $('#loading-progress').hide();
            },
            success:function(result){
                console.log('upload process resultsss:',result);
                alert('처리완료>>>>');
                //serverfile_process(result);    
                
                //output_video_element.src=result.video_result;
                //output_video_element.load();
                let remote_url=result.video_result;
                let xml_request=new XMLHttpRequest();
                xml_request.open('GET',remote_url,true);
                xml_request.responseType='blob';
                xml_request.onreadystatechange = async function(oEvent){
                    console.log('encode vioe filess remote url loadeded xml requets reasstatess:',xml_request.readyState);

                    if(xml_request.readyState===xml_request.DONE){
                        if(xml_request.status===200){
                            let resss=xml_request.response;
                            console.log('ressss:',resss);
                            let blob=new Blob([xml_request.response],{type:'video/mp4'});
                            let url=URL.createObjectURL(blob);
                            console.dir(blob);

                            output_video_element.src=url;
                            output_video_element.load();

                        }
                    }
                }
                xml_request.send();
            },
        });
            
    }

    function video_upload(e){
        console.log('비디오업로드폼 데이터 제출:');
        e.preventDefault();
        let video_uploadform = document.getElementById('video_uploadform');
        let form_data= new FormData(video_uploadform);
        $.ajax({
            url:'/upload_ver2',
            type:'post',
            data: form_data,
            cache:false,
            contentType:false,
            processData:false,
            error:function(jqxHR,textStatus,errorThrown){

            },
            beforeSend:function(){
                $('#video_encodingprogress')[0].style.display='flex';
            },
            complete:function(){
                $('#video_encodingprogress').hide();
            },
            success:function(data){
                console.log('result datatsss:',data);
                
                //let image_extract_form_inputdata=document.getElementById('image_extract_form_data');
                let upload_encoded_form_inputdata=document.getElementById('upload_encoded_form_data');//업로드시에 인코딩처리되어 처리된 결과물 문자열들>>관련(인코딩과정 생략 그냥 업로드된 파일리스트 join형태 구조) 원파일 업로드라면 두개로 쪼개어진 대상 파일들 관련
                let upload_encoded_folderfilepathdata=document.getElementById('upload_encoded_folderfilepathdata');//업로드된 abstract패스경로들..

                //image_extract_form_inputdata.value=data.join(',');//문자열저장화
                let adapt_client_list=data.adapt_client_list;
                let folder_filepath=data.folder_filepath;

                upload_encoded_form_inputdata.value=adapt_client_list.join(',');
                upload_encoded_folderfilepathdata.value=folder_filepath.join(',');

                for(let r=0; r<adapt_client_list.length; r++){
                    
                    let remote_url=adapt_client_list[r];//불러올 url값 바로 적용은 안되는듯하다.
                    console.log('====>>encodings비디오 remote request urlss:',remote_url);

                    let xml_request=new XMLHttpRequest();
                    xml_request.open('GET',remote_url,true);
                    xml_request.responseType='blob';
                    xml_request.onreadystatechange = async function(oEvent){
                        console.log('encode vidoe files remote url loadedds xml request readystatesss:',xml_request.readyState);

                        if(xml_request.readyState===xml_request.DONE){
                            if(xml_request.status===200){
                                let resss=xml_request.response;
                                console.log('ressss:',resss);
                                console.log('get array bufrfersss::',new Blob([xml_request.response],{type:'video/mp4'}));
                                let blob=new Blob([xml_request.response],{type:'video/mp4'});
                                let url=URL.createObjectURL(blob);
                                console.dir(blob);
                                console.log(url);

                                let target_video = document.getElementById('upload_video'+r);
                                target_video.src=url;//blob:url
                                target_video.load();
                                target_video.setAttribute('index',(r+1));
                                console.log('해당 업로드 지정비디오 duration값::::',target_video,target_video.duration);

                                target_video.onloadeddata= function(event){
                                    console.log('타깃비디오 모드 로드시점에 실행>>>:',event.target,event.target.duration,event);

                                    //비디오태그
                                    let normal_target=event.target;
                                    let index=normal_target.getAttribute('index');
                                    console.log('normal_targetss:',normal_target,index);
                                    //take_area
                                    let duration=Math.round(parseFloat(event.target.duration));
                                    let target=document.getElementById(`take${index}_area`);
                                    target.style.display='block';
                                    //take_video(original)
                                    //let target_=document.getElementById(`take${index}`);
                                // target_.setAttribute('original_duration',duration);
                                    //target_.style.width = (3.333 *duration)+'%';
                                    //take_video(abstract edit control element)
                                    let target2=document.getElementById(`control${index}`);
                                    target2.setAttribute('original_duration',duration);
                                    target2.setAttribute('change_duration',duration);
                                    target2.setAttribute('startpos',0);
                                    target2.setAttribute('endpos',0+duration);
                                    target2.style.width = (3.333 * duration)+ '%';

                                    //video wrap visual element
                                    let visual_connect_target=document.getElementById(`take${index}_video`);
                                    //visual_connect_target.style.width=(3.333 * duration)+'%';
                                    //visual_connect_target.style.width=20%;

                                    //각 업로드된 비디오의 duration만큼 자식을 생성한다.
                                    for(let s=0; s<duration; s++){
                                        let make_visible_rangecut=document.createElement('DIV');
                                        make_visible_rangecut.classList.add('visible_range_cut');

                                        let calc_percent_width = ( 100 / duration).toFixed(3);
                                        make_visible_rangecut.style.width = (calc_percent_width)+'%';
                                        make_visible_rangecut.style.left = (calc_percent_width * s)+'%';//0,3.333,....3.3333*n-1의 형태 구조로 처리>>
                                        make_visible_rangecut.setAttribute('time_index',s+1);
                                        visual_connect_target.appendChild(make_visible_rangecut);
                                    }
                                
                                //하단 최종fix위치 지정된 비디오(분할예정된)의 위치배치배정>>
                                }
                            }
                        }
                    }
                    xml_request.send();
                    
                    /*let target_video = document.getElementById('upload_video'+r);
                    target_video.src=adapt_client_list[r];
                    target_video.load();
                    target_video.setAttribute('index',(r+1));
                    console.log('해당 업로드 지정비디오 duration값::',target_video,target_video.duration);

                    let target_video_= document.getElementById('upload_video'+r+'_');
                    target_video_.src=data[r];
                    target_video_.load();
                    target_video_.setAttribute('index',(r+1));*/
  
                }
            }
        });
        return false;
    }
    function onOpenCvReady(){
        //오버레이 관련
        //overlay_dst=new cv.Mat();
       //tmp_image=new cv.Mat();

         /*overlay_origin_src=new cv.Mat(testvideo2.height,testvideo2.width,cv.CV_8UC4);
        overlay_effect_src=new cv.Mat(overlay1.height,overlay1.width,cv.CV_8UC4);

        origin_cap=new cv.VideoCapture(testvideo2);
        overlay_cap=new cv.VideoCapture(overlay1);*/

        //필터관련 및 기타,트랜지션 포함
        //console.log('opencv로드시점 targersrc참조:',target_src);
        //target_src=new cv.Mat();
         // console.log('filesaverss saveAs:',saveAs);
        document.getElementById('status').innerHTML ='OPENCV,.JS IS REaday';

        let rel_target_gathering={};//n개 올린 비디오의 각 between start,endpos 관련 이미지 한개씩 쌍정보 개체들 수집하는 관련된 대기저장

        /*test_extract.addEventListener('click',function(){

            if(!process_possible){
                alert('비디오처리가 불가능한 상태입니다. 출력비디오의 길이가 30초를 넘기는지 확인바랍니다.');
                return false;
            }
            video_between_transition_startendArea.innerHTML='';
            //document.getElementById('testform').submit();
            console.log('whatssss:',select_overlay);
            let select_overlay_value=select_overlay.value;

            let image_extract_form_data = document.getElementById('image_extract_form_data');//추출부분 분할 잘려진 비디오
            let transfer_data={
                'upload_list_data':image_extract_form_data.value,
                'select_overlay':select_overlay.value
            }
            console.log('transfer datasss:',transfer_data);
            //var formdata=new FormData(document.getElementById('uploadform'));
            $.ajax({
                url:'/transition_and_effect_start',//editing최종반영되어진 비디오들입니다.이들 각각 테이크별로 하여 26fps기준으로 하여 모두 해당 프레임률로 자릅니다.영상 이미지로 추출>>
                type:'post',
                data:transfer_data,
                cache:false,
                //contentType:false,
                //processData:false,
                error:function(jqxHR,textStatus,errorThrown){

                },
                beforeSend: function(){
                    console.log('ajax startssss:');
                    $('#loading-progress')[0].style.display='flex';
                },
                complete: function(){
                },
                success:function(result_data){
                    console.log('result datasss;',result_data);
                    //overlay serve randomss..
                    let effect_async_count2=0;//오버레이 serve관련 이미지 로드카운트. 52개 fix
                    let random_overlay_serveframes = result_data.random_overlay_serveframes;//랜덤52장 프레임index요소들!

                    let random_overlay_serveframesArea=document.getElementById('random_overlay_serveframesArea');
                    for(let o=0; o<random_overlay_serveframes.length; o++){
                        let make_image_overlay=document.createElement('IMG');
                        make_image_overlay.width=1280;make_image_overlay.height=720;
                        make_image_overlay.src=random_overlay_serveframes[o];

                        random_overlay_serveframesArea.appendChild(make_image_overlay);
                        make_image_overlay.onload=function(e){
                            console.log('overlay이미지 모드 로드시점실행>>>:',e.target);

                            effect_async_count2++;
                        }
                    }
                    //upload_listss>>
                    let upload_list = result_data.upload_list;
                    let request_id = result_data.request_id;//요청id어떤 요청였었는지 그룹화 구분위함.

                    //video_between_transition_startendArea
                    let video_between_transition_startendArea = document.getElementById('video_between_transition_startendArea');
                    let take_video_imgpart_total = document.getElementById('take_video_imgpart_total');

                    let loop_count = result_data.upload_count;

                    //트랜지션 이미지 처리 관련 async변수 init
                    let transition_async_start=0;
                    let transition_async_end=0;//각 비디오별 시작/끝 지점에 해당하는 값 저장한다.

                    //각 테이크별 전체적인 이미지들의 총 로드성공카운트수 로드성공카운트가 모두 꽉 채운(테이크별합) 경우에 sertInterval clearinterval처리한다>>
                    let effect_async_count=0;
                    
                    //let takeper_distinctfilename_data=[];
                    //let takevideoper_avgframerate_array=result_data.takevideoper_avgframerate_array;//테이크별 비디오의 avgframe초당 보여주는 프레임의수를 가져오고 그 수치와 의 곱을 통해서 맞아떨어지는 avgframerate*duration곱하면 서버에서 전달해준 리스트 개수와 맞게된다. 불일치없어짐.
                    console.log('=====>>>takevideoper avgframerat arraay server serveing datasss:',takevideoper_avgframerate_array);

                    for(let l=0; l<loop_count; l++){//각 업로드 비디오(잘려진 가공처리된)
                        //0:0,1  1:1,2  2:2,3  3:3,4 
                        let now_video_endpoint = result_data.data[(l+1)+'_end_data'];
                        let next_video_startpoint= result_data.data[(l+1+1)+'_start_data'];//첫비디오,n번쨰 비디오가 있을때 다음대상 비디오가 있으면 다음비디오의 첫부분과 지금비디오의 마지막부분의 트랜지션 효과를 부여할뿐임>>
                        let target_full_imgdata=result_data.data[`${l+1}_full_data`];//1,2,3,4,...fulldata 요소를 가져온다.
                        let addon_request_filenamedistinct_data=result_data.data[`${l+1}_full_data_addon`];
                        console.log('video between image transitions standy loopss:',now_video_endpoint,next_video_startpoint,target_full_imgdata);

                        let takevideo_group_element=document.createElement('DIV');
                        takevideo_group_element.classList.add('takevideo_group_imglist');
                        takevideo_group_element.setAttribute('id',`take${l+1}_group`);
                        takevideo_group_element.setAttribute('childlength',target_full_imgdata.length);
                        takevideo_group_element.setAttribute('duration',target_full_imgdata.length / 26);//일단 fix값형태로 26프레임량으로 나눈 duration재생시간값>>
                        takevideo_group_element.setAttribute('requestid',request_id);
                        takevideo_group_element.setAttribute('distinct_request_filename',addon_request_filenamedistinct_data);

                        takeper_distinctfilename_data.push(addon_request_filenamedistinct_data);
                        
                        for(let inner=0; inner<target_full_imgdata.length; inner++){
                            let make_image_part_video=document.createElement('IMG');
                           // make_image_part_video.width=320;
                            //make_image_part_video.height=180;
                            make_image_part_video.width=1280;
                            make_image_part_video.height=720;

                            make_image_part_video.src=target_full_imgdata[inner];
                            make_image_part_video.setAttribute('id',`take${l+1}_img${inner+1}`);
                            make_image_part_video.setAttribute('index',inner+1);
                            takevideo_group_element.appendChild(make_image_part_video);

                            make_image_part_video.onload=function(e){
                                console.log('대상 관련 개체 모두 로드시점때 실행>>:',e.target);

                                effect_async_count++;//임의 테이크안의 세부적 이미지들자식들의 수 로드성공만큼 증가한다.테이크별 이미지전체로드 개수합>>
                            }
                        }
                        take_video_imgpart_total.appendChild(takevideo_group_element);

                        if(next_video_startpoint){
                            //지금 현재 비디오의 마지막장면이미지(한개)
                            let make_image_current=document.createElement('IMG');
                            make_image_current.width=1280; make_image_current.height=720; 
                            make_image_current.src= now_video_endpoint[0];
                            make_image_current.setAttribute('id',`between_${l+1}_start`);//n번째 사이공간의 시작
                            //다음 비디오의 첫번째 장면이미지(한개)
                            let make_image_next = document.createElement('IMG');
                            make_image_next.width=1280; make_image_next.height=720;
                            make_image_next.src= next_video_startpoint[0];
                            make_image_next.setAttribute('id',`between_${l+1}_end`);//n번쨰 사이공간의 끝

                            video_between_transition_startendArea.appendChild(make_image_current);
                            video_between_transition_startendArea.appendChild(make_image_next);

                            make_image_current.onload=function(e){
                                console.log('create elemtn image first개체 다 로드시점실행>>:',e.target);
                                //rel_target_gathering[`${l+1}_start`] = true;
                                
                                rel_target_gathering[`${transition_async_start+1}_start`] = true;//비디오사이별 between의 순번 상관없이 그 순번의 개수를 기준으로 한다 그 between개수만큼을 만족하는 각 bewteen start,end 만 있으면 되니까 그들이 다 모이기만 하면됨.
                                transition_async_start++;
                            }
                            make_image_next.onload=function(e){
                                console.log('create elemtn image after개체 다 로드시점실행>>:',e.target);
                                //rel_target_gathering[`${l+1}_end`] = true;

                                rel_target_gathering[`${transition_async_end+1}_end`] = true;//각 사이 순서상관없는 형태의 무작위형태의 집합들이 모였을때를 고려한다.추적을 하려면 정밀한 클로저설계가 필요함.
                                transition_async_end++;
                            }
                        }
                    }


                    let takevideo_group_element_refer=document.getElementsByClassName('takevideo_group_imglist');
                    console.log(takevideo_group_element_refer);
                    let take_partimgs_totalcnt=0;
                    for(let ss=0; ss<takevideo_group_element_refer.length; ss++){
                        // 각 장면 형상화이고, 각테이크비디오이고 이를 이미지로써 분할한 데이터이다.>>>이들중 리스트중에서 childelgnth개수만큼  img요소가 다 자식 추가되었을때 loaeded된 시점..>떄를 판단>>...
                        let item=takevideo_group_element_refer[ss];
                        let childlength = parseInt(item.getAttribute('childlength'));//자식수
                        let real_childlength=item.children.length;//img태그 자식의 수
                        if(childlength == real_childlength){
                            console.log('==>>>childelgnth;,realchildelngths:',childlength,real_childlength);
                            pass2=true;
                        }else{
                            pass2=false;
                        }
                        take_partimgs_totalcnt += childlength;//총 이미지 데이터 자식의 수
                    }
                    console.log('effect관련 대상들로 쓰일 take별 세부이미지들 로드준비가 모두 되었는지 카운트수==standby수 동일여부 같다면 모두 로드된것:',take_partimgs_totalcnt);
                    
                    let standby = window.setInterval(function(){
                        console.log('===>>관련 이미지대상between들 모두 로드된시점에 실행>>>:',standby, rel_target_gathering);
                        let pass=false;
                        for(let t=0; t<loop_count-1; t++){
                            //3 : 0,1,2 
                            if(rel_target_gathering[`${t+1}_start`] && rel_target_gathering[`${t+1}_end`]){
                                //t:1 2 3 4 5  세개 업로드했다면 그 개수-1 개만큼의 사이공간이 있다는것이고 1,2 between 5개했다면 0~4 0,1,2,3=>1,2,3,4 네개between있어야만 비트윈들에 조건 개수가들이 모두 존재해야만 통과이다 통과안하면 계속 도는것이고 통과되는순간 interval멈춘다 관련사이between대상 object개체이며, 이 원소리스트 집합중 존재했던 경우라면 pass=true
                                pass=true;
                            }else{
                                pass=false;//존재하지 않았던 한 케이스라도 존재하지 않았던 경우라면 
                            }
                        }
                        
                        //이펙트(필터) 관련된 vaild통과관련>>
                        let pass2=false;
                        
                        if(take_partimgs_totalcnt == effect_async_count){
                            pass2=true;
                        }

                        //오버레이 관련된valid통과관련
                        let pass3=false;
                        if( 52 == effect_async_count2){
                            pass3=true;
                        }
                        console.log('===>>데이터 gathering full여부(트랜지션,필터,오버레이 모두):',pass,pass2,pass3);
                        if(pass && pass2 &&pass3){
                            
                            window.clearInterval(standby);
                            //alert('필요한 이미지(트랜지션,이펙트적용) 로드 재료는 모두 준비완료!!');
                            //반복호출실행을 멈추고, image_write_front실행>>
                            image_transition_overlay_filterEffect_front(loop_count,upload_list,request_id, takeper_distinctfilename_data,takevideoper_avgframerate_array);//filter and transitionsss
                        }
                    },20);
                    document.getElementById('firstimage').width=1280;
                    document.getElementById('firstimage').height=720;
                    document.getElementById('secondimage').width=1280;
                    document.getElementById('secondimage').height=720;
                    document.getElementById('firstimage').src=data['1_data'][1];
                    document.getElementById('secondimage').src=data['2_data'][0];

                    //let url=URL.createObjectURL(data);
                    //console.log('urlsss read 가능??:',url);
                    //http://localhost:3000/processfiles/xxxxxxxxresultfile.mp4

                    firstimage.onload=function(e){
                        console.log('파일이 다 로드된시점에 실행:::',e.target);
                        rel_target_gathering['1']=true;
                    }
                    secondimage.onload=function(e){
                        console.log('파일이 다 로드된시점에 실행:::',e.target);
                        rel_target_gathering['2']=true;
                    }

                    let standby = window.setInterval(function(){
                        console.log('===>이미지파일로드 src다 둘다 지정된경우에 실행>>>:',standby,rel_target_gathering);
                        if(rel_target_gathering['1'] && rel_target_gathering['2']){
                            window.clearInterval(standby);
                            //let src1=cv.imread(firstimage);
                            //let src2=cv.imread(secondimage);
                            //console.log('src1:',src1);
                            //console.log('src2:',src2);

                            image_write_front();
                        }
                    },10);
                    
                    //video_source_element.src='http://localhost:3000/processfiles/'+data.video_result;
                    //video_element.load();
                }
            });    
        },false);*/

        test_extract.addEventListener('click',image_transition_overlay_filterEffect_front,false);

        original_to_videoEdit.addEventListener('click',async function(){
            //클라이언트에서 처리하는것으로 바꿉니다!!! 인코딩비디오 -> 각 테이크별로 자른 구간에 대해서만 프레임분할로직->각 takerow별 장면전환별 start,endpos이미지 배정 및 각 take별 전체프레임분할setting리스트구현>> 프레임분할된 이미지들을 기반으로 하여 삭제하지말고 그대로 이어서 테이크별로 그들끼리 이어붙여 video fps26으로 만들기!및 표현

            //document.getElementById('testform').submit();
            //alert('원본비디오수정처리하는관련 돼나?');
            console.log('original to video Edit process gogo:');

            let upload_encoded_form_data = document.getElementById('upload_encoded_form_data');//업로드가 될 원본 엔코딩 영상들 그 각각을 그 각각에 연결되어있는 split정보와 함께 보내어서 영상을 가공 자른다.
            //let upload_encoded_folderfilepathdata = document.getElementById('upload_encoded_folderfilepathdata');//이걸로 실제로 사용해야한다.
            let upload_encoded_takevideos= upload_encoded_form_data.value.split(',');

            let split_and_move_video_controls= document.getElementsByClassName('take_row');
            let take_video_process_info = [];

            if(upload_encoded_form_data.value=='' || split_and_move_video_controls.length==0){
                alert('처리할 관련 정보가 없습니다!.');
                return false;
            }

            let transfer_data={
                'upload_list_data':image_extract_form_data.value,
                'select_overlay':select_overlay.value
            }
            console.log('transfer datasss:',transfer_data);

            let request_id;
            let effect_async_count2=0;//오버레이 serve관련 이미지 로드 카운트

            //var formdata=new FormData(document.getElementById('uploadform'));
            $.ajax({
                url:'/transition_and_effect_start',
                type:'post',
                data:transfer_data,
                cache:false,
                //contentType:false,
                //processData:false,
                error:function(jqxHR,textStatus,errorThrown){

                },
                beforeSend: function(){
                    console.log('ajax startssss:');
                    $('#loading-progress')[0].style.display='flex';
                },
                complete: function(){
                },
                success:function(result_data){
                    console.log('result datasss;',result_data);
                    //overlay serve randomss..
                    let random_overlay_serveframes = result_data.random_overlay_serveframes;//랜덤52장 프레임index요소들!
                    request_id=result_data.request_id;

                    let random_overlay_serveframesArea=document.getElementById('random_overlay_serveframesArea');
                    for(let o=0; o<random_overlay_serveframes.length; o++){
                        let make_image_overlay=document.createElement('IMG');
                        make_image_overlay.width=1280;make_image_overlay.height=720;
                        make_image_overlay.src=random_overlay_serveframes[o];

                        random_overlay_serveframesArea.appendChild(make_image_overlay);
                        make_image_overlay.onload=function(e){
                            console.log('overlay이미지 모드 로드시점실행>>>:',e.target);

                            effect_async_count2++;
                        }
                    }
                }
            });
            
            let change_duration_sum=0;
            for(let s=0; s<split_and_move_video_controls.length; s++){
                if(split_and_move_video_controls[s].style.display=='block'){
                    //block인항목들에 대해서만 >>
                    //let item=split_and_move_video_controls[s];
                    let item=document.getElementById(`control${s+1}`);
                    //순차적 테이크 순서 절대적인 1~5순서쌍 정보>>>
                    let take_index=s+1;
                    let original_duration = parseInt(item.getAttribute('original_duration'));
                    let change_duration=parseInt(item.getAttribute('change_duration'));
                    let startpos = parseInt(item.getAttribute('startpos'));
                    let endpos = parseInt(item.getAttribute('endpos'));
                    
                    if(startpos < 0){
                        alert('프레임범위가 원본비디오를 벗어났습니다.');
                        return false;
                    }
                    if(change_duration > original_duration){
                        alert('원본 비디오 길이보다 더 길게 지정은 불가합니다.');
                        return false;
                    }
                    if(endpos > original_duration){
                        alert('프레임범위가 원본비디오를 벗어났습니다.');
                        return false;
                    }

                    change_duration_sum += change_duration;

                    let store_obj= {};
                    store_obj['take'] = take_index;
                    store_obj['duration'] = change_duration;
                    store_obj['startpos'] = startpos;
                    store_obj['endpos'] = endpos; 

                    take_video_process_info.push(store_obj);
                }               
            }
            console.log('=--->>>changeDuraiton sum:',change_duration_sum);
            if(change_duration_sum >30){
                process_possible=false;
                alert('출력결과물의 경우 30초를 넘을수없습니다.');
                return false;
            }
            /*let transfer_data={
                'upload_list_data':upload_encoded_form_data.value,
                'upload_list_data_use':upload_encoded_folderfilepathdata.value,
                'edit_process_info' : JSON.stringify(take_video_process_info)
            }
            console.log('transfer datasss:',transfer_data);*/
            //var formdata=new FormData(document.getElementById('uploadform'));

            process_possible=true;
            /*server 요청하지 않습니다.
            $.ajax({
                url:'/video_move_and_splice_process',
                type:'post',
                data:transfer_data,
                cache:false,
                //contentType:json,
                //dataType:'json',
                //processData:false,
                error:function(jqxHR,textStatus,errorThrown){

                },
                beforeSend: function(){
                    //console.log('ajax startssss:');
                    //$('#loading-progress')[0].style.display='flex';
                },
                complete: function(){
                // $('#loading-progress').hide();
                },
                success:function(result_data){
                    console.log('result datasss;',result_data);
                    
                    //editivineg 처리되어 나온 그 대상파일들이 있을것이고 그들을 기억하고 그 정보 바탕으로 하여 그대로 이어서 관련 처리>>트랜지션등 이어서 처리>.....
                    let image_extract_form_inputdata = document.getElementById('image_extract_form_data');
                    let process_data=result_data.prcess_data;//dns s3 url포함한 경로path
                    //let s3_now_url =result_data.s3_now_url;

                    image_extract_form_inputdata.value=process_data.join(',');
                    for(let r=0; r<process_data.length; r++){
                        let target_video = document.getElementById('upload_edited_video'+r);
                        target_video.src=process_data[r];
                        target_video.load();
                        target_video.setAttribute('index',(r+1));
                        console.log('해당 업로드 지정비디오 duration값:::',target_video,target_video.duration);
                    }
                }
            });*/
            console.log('====>>테이크별 분할할 관련정보 바로 ffmpeg.wasm클라이언트에서 처리합니다. 회의내용반영::',take_video_process_info);

            //ffmpegwasm을 사용합니다!
            if(!ffmpeg.isLoaded()){
                await ffmpeg.load();
            } 

            message.innerHTML='Loading data';
            let rel_target_gathering={};//n개 올린 비디오의 각 betseen start,endpos관련 이미지 한개씩 상정보 객체 대기저장

            //let random_overlay_serveframes= result_data.random_overlay_serveframes;

            /*
            for(let o=0; o<random_overlay_serveframes.length; o++){
                let make_image_overlay=document.createElement('IMG');
                make_image_overlay.width=1280;make_image_overlay.height=720;
                make_image_overlay.src=random_overlay_serveframes[o];

                random_overlay_serveframesArea.appendChild(make_image_overlay);
                make_image_overlay.onload=function(e){
                    console.log('overlay이미지 모두 로드 시점실행>>:',e.target);

                    deffect_async_count2++;
                }
            }
            */

            //upload_olistss>

            //let request_id=make_id();요청을 구분하기위함.

            //video_+bettwen_transition_startendarea
            let video_between_transition_startendArea=document.getElementById('video_between_transition_startendArea');
            let take_video_imgpart_total = document.getElementById('take_video_imgpart_total');

            video_between_transition_startendArea.innerHTML='';

            let loop_count = take_video_process_info.length;//테이크 업로드 카운트수

            //트랜지션 이미지 처리 관련 async 변수 init
            let transition_async_start=0;
            let transition_async_end=0;//각 비디오별 시작/끝 지점에 해당값 저장한다.
            //각 테이크별 전체적 이미지들 총 로드성공카운트수가 모두 꽉 채운 (테이크별합) 경우에 setInterval clearinterval처리한다>>
            let effect_async_count = 0;

            //let bloburl_list=[];//메모리변수들을 담을 그릇 이것들을 다 완료후에 일괄비운다.메모리저장공간자체크기는 별로 안큼.
            let blob_list=[];

            for(let f=0; f<upload_encoded_takevideos.length; f++){
                let videoEdit_info=take_video_process_info[f];//각 인코딩업로드 비디오입니다.및 편집정보rows
                let startpos=videoEdit_info['startpos'];
                let endpos=videoEdit_info['endpos'];
                let duration=videoEdit_info['duration'];//각 테이크별 자른 duration길이값만큼의 영상이 생성되어야하고, 그만큼의 프레임률*duration의 프레임들이 생성되어야함.

                let input_read_url=upload_encoded_takevideos[f];//각 테이크별 비디오
                ffmpeg.FS('writeFile',`takevideo${f+1}.mp4`,await fetchFile(input_read_url));//테이크별 encoding비디오를 읽습니다.MSMEF?가상저장소 상에 메모리형태로 저장추정 unlink필요
                
                await ffmpeg.run('-i',`takevideo${f+1}.mp4`,'-ss',`${startpos}`,'-t',`${duration}`,'-r','26','-f','image2',`takevideo${f+1}_frame_%d.png`);//takevideo1_frame_1,2,3,3....

                let takevideo_group_element = document.createElement('DIV');
                takevideo_group_element.classList.add('takevideo_group_imglist');
                takevideo_group_element.setAttribute('id',`take${f+1}_group`);
                takevideo_group_element.setAttribute('childlength',26*duration);
                takevideo_group_element.setAttribute('duration',duration);//각 테이크별 듀레이션값.
                //takevideo_group_element.setAttribute('requestid',request_id);

                for(let inner=0; inner<(26*duration); inner++){//각 테이크별 자른 구간duration만큼의 편집형대대로 그 형상대로 프레임전체분할한다.그 구간만 분할하면된다.구간만큼만
                    let read_index = inner+1;
                    console.log('read_index value: file reading!',read_index);
                    let data=ffmpeg.FS('readFile',`takevideo${f+1}_frame_${read_index}.png`);//takevideo1,2,3_frame_1,2,3,4,....비디오별 구간프레임분할전체이미지 MSMEF가상저장소있는것 readFile
                    console.log('분할된 이미지 프레임 관련된 처리>>이미지별 이미지특정한개 관련 리드파일관련 정보get:',data,data.buffer);
                    //console.dir(new Uint8Array(data.buffer));//arrraybuffer->uint8array
                    let arraybufferconvert= new Uint8Array(data.buffer);
                    console.dir(arraybufferconvert);

                    let blob_convert= new Blob([arraybufferconvert],{type:"image/png"});//블롭변환 unint8array rel arraybuffer to blob store
                    arraybufferconvert=null;
                    delete(arraybufferconvert);
                    
                    blob_list.push(blob_convert);

                    let image_create= document.createElement('IMG');
                    console.log('blob converstionalss:',blob_convert);
                    //console.log('create blob ulrsss:',URL.createObjectURL(blob_convert));
                    //let local_url=URL.createObjectURL(blob_convert);
                    image_create.src = URL.createObjectURL(blob_convert);;//테이크별 구간별 세부 프레임한개를 가상imgcreate생성
                    //URL.revokeObjectURL(image_create.src);
                    //bloburl_list.push(local_url);

                    image_create.setAttribute('id',`take${f+1}_img${inner+1}`);
                    image_create.setAttribute('index',inner+1);
                    takevideo_group_element.appendChild(image_create);

                    image_create.onload=function(e){
                        console.log('===>>대상 관련 개체 모두 로드시점때 실행>>>:',e.target,this);

                        effect_async_count++;//임의 테이크안의 세부적 이미지들프레임들의 수 로드 성공한 카운트만큼 증가한다. 테이크별 이미지 전체로드 개수합

                        //URL.revokeObjectURL(this.src);
                    }

                    let make_image_next;
                    let make_image_current;

                    if(inner==0){
                        console.log('===>테이크별 구간splice비디오 잘려진 프레임 가장 첫프레임 각 테이크비디오의 시작부 프레임');

                        if(f!=0){
                            //첫번째 테이크비디오에 대해선 트랜지션 끝부분을 저장하는것 필요없음.
                            make_image_next= document.createElement('IMG');
                           // let local_urls=URL.createObjectURL(blob_convert);
                            make_image_next.src= URL.createObjectURL(blob_convert);
                            //URL.revokeObjectURL(local_urls);//해제해도 이미 내부적으로 처리됨. copy개념임. 메모리공유가 아님.
                            //bloburl_list.push(local_urls);

                            make_image_next.setAttribute('id',`between_${f}_end`);//각 2,3,4,..테이크비디오라고하면 그 비디오의 각 시작부분은 테이크수-1 테이크index-1 between번째index의 끝end이다.
                            video_between_transition_startendArea.appendChild(make_image_next);

                            make_image_next.onload=function(e){
                                console.log('create elemnt image after개체 다 로드시점실행:',e.target,this);

                                rel_target_gathering[`${transition_async_end+1}_end`]=true;
                                transition_async_end++;

                                //URL.revokeObjectURL(this.src);
                            }
                        }
                                                                    
                    }else if(inner== (26*duration)-1){
                        console.log('===>테이크별 구간pslice비디오 잘려진 프레임 가장 마지막프레임 각 테이크비디오의 마지막프레임:');

                        if(f!=4){
                            make_image_current = document.createElement('IMG');
                            //let local_urls=URL.createObjectURL(blob_convert);
                            make_image_current.src = URL.createObjectURL(blob_convert);
                            //URL.revokeObjectURL(local_urls);
                            //bloburl_list.push(local_urls);

                            make_image_current.setAttribute('id',`between_${f+1}_start`);//1,2,3,4번째 비디오에 대해서만 이며, 그 수치대로 각 between의 시작부이다.
                            video_between_transition_startendArea.appendChild(make_image_current);

                            make_image_current.onload= function(e){
                                console.log('create elemtn image first개체 다 로드시점실행:',e.target,this);

                                rel_target_gathering[`${transition_async_start+1}_start`] = true;
                                transition_async_start++;

                                //URL.revokeObjectURL(this.src);
                            }
                        }                      
                    }
                      
                    console.log('file unlinkk detlee readindex:',read_index);
                    ffmpeg.FS('unlink',`takevideo${f+1}_frame_${read_index}.png`);
                }
                take_video_imgpart_total.appendChild(takevideo_group_element);

                //메모리 해제합니다!!
                ffmpeg.FS('unlink',`takevideo${f+1}.mp4`);//테이크비디오 가상메모리개체 삭제
                /*for(let innerss=0; innerss<(26*duration); innerss++){
                    ffmpeg.FS('unlink',`takevideo${f+1}_frame_${innerss+1}.png`);
                }*/
                console.log('====>>각 인코딩 outer loopp완료별 ffmpeg 관련 메모리자원해제!!!!=================endss');
            }
            //메모리 남은것 싹다 비워버리기===================>>>
            /*for(let del=0; del<bloburl_list.length; del++){
                let delete_target=bloburl_list[del];//관련변수 객체 리보크
                console.log('삭제 대상 url타깃:',delete_target);
                URL.revokeObjectURL(delete_target);//메모리해제  fileurl해ㅐ제.
            }*/
            for(let del=0; del<blob_list.length; del++){
                let delete_target=blob_list[del];
                console.log('삭제대상 관련 deltetargetss:',delete_target);
                delete_target=null;
                delete(delete_target);
            }

            let takevideo_group_element_refer=document.getElementsByClassName("takevideo_group_imglist");
            console.log(takevideo_group_element_refer);
            let take_partimgs_totalcnt=0;
            for(let ss=0; ss<takevideo_group_element_refer.length; ss++){
                let item=takevideo_group_element_refer[ss];
                let childlength = parseInt(item.getAttribute('childlength'));
                take_partimgs_totalcnt += childlength;//총 이미지 데이터 자식수.
            }
            console.log('effect관련 대상들로 쓰일 take별 세부이미지들 로드 준비가 모두 되었는지 카운트수==standby수 동일여부 같다면 모두 로드된것:',take_partimgs_totalcnt);

            let secure_standby_count=0;
            let standby = window.setInterval(function(){
                console.log('===>>관련 이미지대상between들 모두 로드완료시점에 실행>>>:',standby,rel_target_gathering);
                console.log(take_partimgs_totalcnt,effect_async_count);
                console.log(effect_async_count2);

                let pass=false;
                if(loop_count!=1){
                    for(let t=0; t<loop_count-1; t++){
                        if(rel_target_gathering[`${t+1}_start`] && rel_target_gathering[`${t+1}_end`]){
                            pass=true;
                        }else{
                            pass=false;
                        }
                    }
                }else{
                    pass=true;
                }
                
                //이펙트 필터 관련된 vaild통과관련
                let pass2=false;
                if(take_partimgs_totalcnt == effect_async_count){
                    pass2=true;
                }
                
                //오버레이 관련된 vaild통과관련
                let pass3=false;
                if(52 == effect_async_count2){
                    pass3= true;
                }

                console.log('===>>준비 데이터 gathering full여부(트랜지션,필터,오버레이등):',pass,pass2,pass3);
                if( pass && pass2 && pass3){
                    window.clearInterval(standby);

                    console.log('=====>준비 데이터 모두 완료!!!',rel_target_gathering);

                    test_extract.setAttribute('request_id',request_id);
                    test_extract.setAttribute('loop_count',upload_encoded_takevideos.length);
                }

                if(secure_standby_count==10000){
                    //50*10000=>5000,00 500초이후에도 안된다면 반복되어도 안된다면 종료
                    alert('프로그램 종료!:');
                    window.clearInterval(standby);
                }
                secure_standby_count++;
            },50);
        },false);
    }
</script>
<script type="text/javascript">
    //오버레이 프리뷰..!
    /*let overlay_captureing=document.getElementById('overlay_captureing');
    overlay_captureing.addEventListener('click',overlay_processStart,false);
   
    let target_overlay;
    let timeoutid;
    function overlay_processStart(){
        let selected_overlay=select_overlay.value;
        target_overlay=document.getElementById('overlay'+selected_overlay);
        console.log('target_overlayss:',target_overlay);
        target_overlay.play();
        testvideo2.play();
        processVideoOverlay(target_overlay);
    }
    function processVideoOverlay(){
        console.log('processVieoooverlayss:',target_overlay,timeoutid);
        try{
            let begin=Date.now();
            origin_cap = new cv.VideoCapture(testvideo2);
            overlay_cap=new cv.VideoCapture(target_overlay);
            
            origin_cap.read(overlay_origin_src);
            overlay_cap.read(overlay_effect_src);

            cv.imshow('canvasinput00',overlay_origin_src);
            cv.imshow('canvasinput01',overlay_effect_src);

            let delay=1000/26 - (Date.now() - begin);

            overlay_callback();

            timeoutid=setTimeout(processVideoOverlay,delay);
        }catch(error){
            console.log('errosss:',error);
        }
    }
    function processVideoOverlay_(target_src){
        try{
            let begin=Date.now();
            //origin_cap = new cv.VideoCapture(testvideo2);
            overlay_cap=new cv.VideoCapture(target_overlay);
            
            //origin_cap.read(overlay_origin_src);
            overlay_cap.read(overlay_effect_src);

            //cv.imshow('canvasinput00',overlay_origin_src);
            cv.imshow('canvasinput01',overlay_effect_src);

            let delay=1000/26 - (Date.now() - begin);

            overlay_callback();

            timeoutid=setTimeout(processVideoOverlay,delay);
        }catch(error){
            console.log('errosss:',error);
        }
    }

    function overlay_callback(){
        try{
            let alpha=0.65;
            let beta=0.35;

            let src1=cv.imread(canvasinput00);
            let src2=cv.imread(canvasinput01);

            let dst=new cv.Mat();
            cv.addWeighted(src1,1,src2,0.72,0.0,dst,-1);
            cv.imshow(canvasoutput00,dst);

            dst.delete();src1.delete();src2.delete();
        }catch(error){
            console.log('what erross:',error);
        }
    }*/

    let select_overlay=document.getElementById('select_overlay');

    //필터처리관련..
    let utils = new Utils('errorMessage');
    
    let width = 0;
    let height = 0;
    
    let resolution = window.innerWidth < 960 ? 'qvga' : 'vga';
    
    // whether streaming video from the camera.
    let streaming = false;
    
    let testvideo = document.getElementById('videoInput');
    let vc = null;
    
    let container = document.getElementById('container');
    
    let lastFilter = '';
    let src = null;
    let dstC1 = null;//전역변수를 해제할수는 없기에, 지역변수화하고 처리후에 바로 메모리해제하는게 성능상 더 나을것임.,
    let dstC3 = null;
    let dstC4 = null;
    
    function startVideoProcessing() {
        //src = new cv.Mat(height, width, cv.CV_8UC4);
        //dstC1 = new cv.Mat(height, width, cv.CV_8UC1);
        //dstC3 = new cv.Mat(height, width, cv.CV_8UC3);
        //dstC4 = new cv.Mat(height, width, cv.CV_8UC4);

        //console.log('startvVideo processings:',src);
        requestAnimationFrame(processVideo);
    }
    //원본영상 그대로 출력!
    function passThrough(src) {
        console.log('passThroughtss src:',src);//target_src를 바로 받아서 이를 바로 리턴하고 외부에서 처리후에 target_src해제하는 형태로.
        return src;
    }
    //gray 모드 출력>>cv.Color_rgba2gray
    function gray(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);//채널한개짜리 mat공간을 생성을 바로 한후에 외부에 전달한다, 외부에서 이를 해제하는형태로 한다. 외부에서 건내준target_src,전달 dstc1메모리해제해준다.
        //cv.cvtColor(src, dstC1, cv.COLOR_RGBA2GRAY);
        cv.cvtColor(src, dstc1, cv.COLOR_RGBA2GRAY);

        src.delete();//target_src넘겨준것은 원본관련하여 처리후에 삭제하고->처리후에 return개체는 밖에서 받아서 처리후 삭제한다.
        return dstc1;
    }
    //hsv변환관련 출력>>cv.color_rgba2rgb, cv.color_rgb2hsv
    function hsv(src) {
        let dstc3=new cv.Mat(src.rows,src.cols,cv.CV_8UC3);
        //cv.cvtColor(src, dstC3, cv.COLOR_RGBA2RGB);
        //cv.cvtColor(dstC3, dstC3, cv.COLOR_RGB2HSV);
        cv.cvtColor(src,dstc3,cv.COLOR_RGBA2RGB);
        cv.cvtColor(dstc3,dstc3,cv.COLOR_RGB2HSV);

        src.delete();
        //return dstC3;
        return dstc3;//외부에서 dstc3지역변수개체mat메모리해제, 외부전달target_src바로해제
    }
    //케니변환 임계값 최소최대였던가 
    function canny(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        cv.cvtColor(src,dstc1,cv.COLOR_RGBA2GRAY);
        cv.Canny(dstc1,dstc1,controls.cannyThreshold1,controls.cannyThreshold2,controls.cannyApertureSize,controls.cannyL2Gradient);
        //cv.cvtColor(src, dstC1, cv.COLOR_RGBA2GRAY);
        /*cv.Canny(dstC1, dstC1, controls.cannyThreshold1, controls.cannyThreshold2,
                 controls.cannyApertureSize, controls.cannyL2Gradient);*/
        //return dstC1;
        src.delete();

        return dstc1;
    }
    //범위출력>>
    function inRange(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        console.log('hmm src target targetsrc mat width,height image pixelss',src.cols,src.rows);
        let lowValue = controls.inRangeLow;
        let lowScalar = new cv.Scalar(lowValue, lowValue, lowValue, 255);
        let highValue = controls.inRangeHigh;
        let highScalar = new cv.Scalar(highValue, highValue, highValue, 255);
        //let low = new cv.Mat(height, width, src.type(), lowScalar);
        //let high = new cv.Mat(height, width, src.type(), highScalar);
        let low = new cv.Mat(src.rows,src.cols,src.type(), lowScalar);
        let high = new cv.Mat(src.rows,src.cols,src.type(), highScalar);
        console.log('inRange test:',src.type(),lowScalar,dstc1);
        cv.inRange(src, low, high, dstc1);
        low.delete(); high.delete();src.delete();
        return dstc1;//dstc1해제하고, 외부전달준 targetsrc외부에서 해제.
    }
    //임계점
    function threshold(src) {
        let dstc4= new cv.Mat(src.rows,src.cols,cv.CV_8UC4);//채널4개짜리mat매트릭스 생성 메모리공간 생성.
        cv.threshold(src, dstc4, controls.thresholdValue, 200, cv.THRESH_BINARY);
        src.delete();
        return dstc4;
    }
    //적응형 임계점api
    function adaptiveThreshold(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        console.log('targetsrc rows,height width,height??:',src.cols,src.rows);
        //let mat = new cv.Mat(height, width, cv.CV_8U);
        let mat =new cv.Mat(src.rows,src.cols,cv.CV_8U);
        cv.cvtColor(src, mat, cv.COLOR_RGBA2GRAY);
        cv.adaptiveThreshold(mat, dstc1, 200, cv.ADAPTIVE_THRESH_GAUSSIAN_C,
                             cv.THRESH_BINARY, Number(controls.adaptiveBlockSize), 2);
        mat.delete();src.delete();
        return dstc1;
    }
    //가우시안블러
    function gaussianBlur(src) {
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        cv.GaussianBlur(src, dstc4,
                        {width: controls.gaussianBlurSize, height: controls.gaussianBlurSize},
                        0, 0, cv.BORDER_DEFAULT);
        src.delete();
        return dstc4;
    }

    //바이레탈필터블러
    function bilateralFilter(src) {
        let dstc3=new cv.Mat(src.rows,src.cols,cv.CV_8UC3);
        let mat = new cv.Mat(src.rows, src.cols, cv.CV_8UC3);
        cv.cvtColor(src, mat, cv.COLOR_RGBA2RGB);
        cv.bilateralFilter(mat, dstc3, controls.bilateralFilterDiameter, controls.bilateralFilterSigma,
                           controls.bilateralFilterSigma, cv.BORDER_DEFAULT);
        mat.delete();src.delete();
        return dstc3;
    }
    //연산정도가 큰편.
    function medianBlur(src) {
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        cv.medianBlur(src, dstc4, controls.medianBlurSize);
        src.delete();
        return dstc4;
    }
    //소벨함수
    function sobel(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        console.log('sobel filter functions targersrcsss width,heights:',src.cols,src.rows);
        //let mat = new cv.Mat(height, width, cv.CV_8UC1);
        let mat = new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        cv.cvtColor(src, mat, cv.COLOR_RGB2GRAY, 0);
        cv.Sobel(mat, dstc1, cv.CV_8U, 1, 0, controls.sobelSize, 1, 0, cv.BORDER_DEFAULT);
        mat.delete();src.delete();
        return dstc1;
    }
    
    function scharr(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        console.log('scharrr exeuctess functions targetsrc width,heightss:',src.cols,src.rows);
        //let mat = new cv.Mat(height, width, cv.CV_8UC1);
        let mat =new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        cv.cvtColor(src, mat, cv.COLOR_RGB2GRAY, 0);
        cv.Scharr(mat, dstc1, cv.CV_8U, 1, 0, 1, 0, cv.BORDER_DEFAULT);
        mat.delete();src.delete();
        return dstc1;
    }
    
    function laplacian(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        console.log('laplcaisin exeuctes functions targetsrc rowss,width,height:',src.cols,src.rows);
        //let mat = new cv.Mat(height, width, cv.CV_8UC1);
        let mat =new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        cv.cvtColor(src, mat, cv.COLOR_RGB2GRAY);
        cv.Laplacian(mat, dstc1, cv.CV_8U, controls.laplacianSize, 1, 0, cv.BORDER_DEFAULT);
        mat.delete();src.delete();
        return dstc1;
    }
    
    let contoursColor = [];
    for (let i = 0; i < 10000; i++) {
        contoursColor.push([Math.round(Math.random() * 255),
                            Math.round(Math.random() * 255),
                            Math.round(Math.random() * 255), 0]);
    }
    //contours
    function contours(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        console.log('contourss function sexecutresss targetsrc width,height:',src.cols,src.rows);
        cv.cvtColor(src, dstc1, cv.COLOR_RGBA2GRAY);
        cv.threshold(dstc1, dstc4, 120, 200, cv.THRESH_BINARY);
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(dstc4, contours, hierarchy,
                        Number(controls.contoursMode),
                        Number(controls.contoursMethod), {x: 0, y: 0});
        //dstc3.delete();
       // dstC3 = cv.Mat.ones(height, width, cv.CV_8UC3);
       let dstc3 = cv.Mat.ones(src.rows,src.cols,cv.CV_8UC3);
        for (let i = 0; i<contours.size(); ++i) {
            let color = contoursColor[i];
            cv.drawContours(dstc3, contours, i, color, 1, cv.LINE_8, hierarchy);
        }
        contours.delete(); hierarchy.delete();
        dstc1.delete();dstc4.delete();src.delete();
        return dstc3;
    }
    //히스토그램(밝기량 표현, 도표형태)
    function calcHist(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        cv.cvtColor(src, dstc1, cv.COLOR_RGBA2GRAY);
        let srcVec = new cv.MatVector();
        srcVec.push_back(dstc1);
        let scale = 2;
        let channels = [0];
        let histSize = [src.cols/scale];
        const ranges = [0, 255];
        let hist = new cv.Mat();
        let mask = new cv.Mat();
        let color = new cv.Scalar(0xfb, 0xca, 0x04, 0xff);
        cv.calcHist(srcVec, channels, mask, hist, histSize, ranges);
        let result = cv.minMaxLoc(hist, mask);
        let max = result.maxVal;
        cv.cvtColor(dstc1, dstc4, cv.COLOR_GRAY2RGBA);
        // draw histogram on src
        for (let i = 0; i < histSize[0]; i++) {
            let binVal = hist.data32F[i] * src.rows / max;
            cv.rectangle(dstc4, {x: i * scale, y: src.rows - 1},
                         {x: (i + 1) * scale - 1, y: src.rows - binVal/3}, color, cv.FILLED);
        }
        srcVec.delete();
        mask.delete();
        hist.delete();
        dstc1.delete();src.delete();
        return dstc4;
    }
    //이퀄라이즈
    function equalizeHist(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        cv.cvtColor(src, dstc1, cv.COLOR_RGBA2GRAY, 0);
        cv.equalizeHist(dstc1, dstc1);
        src.delete();
        return dstc1;
    }
    
    let base;
    //백프로젝션
    function backprojection(src) {
        let dstc1=new cv.Mat(src.rows,src.cols,cv.CV_8UC1);
        let dstc3=new cv.Mat(src.rows,src.cols,cv.CV_8UC3);
        if (lastFilter !== 'backprojection') {
            if (base instanceof cv.Mat) {
                base.delete();
            }
            base = src.clone();
            cv.cvtColor(base, base, cv.COLOR_RGB2HSV, 0);
        }
        cv.cvtColor(src, dstc3, cv.COLOR_RGB2HSV, 0);
        let baseVec = new cv.MatVector();
        let targetVec = new cv.MatVector();
        baseVec.push_back(base); targetVec.push_back(dstc3);
        let mask = new cv.Mat();
        let hist = new cv.Mat();
        let channels = [0];
        let histSize = [50];
        let ranges;
        if (controls.backprojectionRangeLow < controls.backprojectionRangeHigh) {
            ranges = [controls.backprojectionRangeLow, controls.backprojectionRangeHigh];
        } else {
            return src;
        }
        cv.calcHist(baseVec, channels, mask, hist, histSize, ranges);
        cv.normalize(hist, hist, 0, 255, cv.NORM_MINMAX);
        cv.calcBackProject(targetVec, channels, hist, dstc1, ranges, 1);
        baseVec.delete();
        targetVec.delete();
        mask.delete();
        hist.delete();dstc3.delete();src.delete();
        return dstc1;
    }
    //침식
    function erosion(src) {
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        let kernelSize = controls.erosionSize;
        let kernel = cv.Mat.ones(kernelSize, kernelSize, cv.CV_8U);
        let color = new cv.Scalar();
        cv.erode(src, dstc4, kernel, {x: -1, y: -1}, 1, Number(controls.erosionBorderType), color);
        kernel.delete();src.delete();
        return dstc4;
    }
    //팽창
    function dilation(src) {
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        let kernelSize = controls.dilationSize;
        let kernel = cv.Mat.ones(kernelSize, kernelSize, cv.CV_8U);
        let color = new cv.Scalar();
        cv.dilate(src, dstc4, kernel, {x: -1, y: -1}, 1, Number(controls.dilationBorderType), color);
        kernel.delete();src.delete();
        return dstc4;
    }
    //모폴로지(윤곽선 연산)
    function morphology(src) {
        let dstc3=new cv.Mat(src.rows,src.cols,cv.CV_8UC3);
        let dstc4=new cv.Mat(src.rows,src.cols,cv.CV_8UC4);
        let kernelSize = controls.morphologySize;
        let kernel = cv.getStructuringElement(Number(controls.morphologyShape),
                                              {width: kernelSize, height: kernelSize});
        let color = new cv.Scalar();
        let op = Number(controls.morphologyOp);
        let image = src;//메모리공간이 추가생성은 아니고,공유한다.밖에서 targetsrc를 어차피 해제한다면 여기서 삭제할시에 밖에서 삭제시 문제?발생여지있음.
        if (op === cv.MORPH_GRADIENT || op === cv.MORPH_TOPHAT || op === cv.MORPH_BLACKHAT) {
            cv.cvtColor(src, dstc3, cv.COLOR_RGBA2RGB);
            image = dstc3;
        }
        cv.morphologyEx(image, dstc4, op, kernel, {x: -1, y: -1}, 1,
                        Number(controls.morphologyBorderType), color);
        kernel.delete();dstc3.delete();src.delete();//image는 자동으로 메모리공간주소 참조를 잃게된다.
        return dstc4;
    }
    
    function processVideo() {
        let src=new cv.Mat(testvideo.height,testvideo.width,cv.CV_8UC4);
        if (!streaming) return;
        stats.begin();
        vc.read(src);//프리뷰 비디오읽은 프레임mat데이터 저장 지정한다.
        let result;//리턴받는 mat변수를 참조하는 변수 메모리공유하기에 이걸 해제하면 그 공유된 메모리도 삭제가능하다.
        console.log('now controslss contorls.filters:',controls,controls.filter);
        switch (controls.filter) {
            case 'passThrough': result = passThrough(src); break;
            case 'gray': result = gray(src); break;
            case 'hsv': result = hsv(src); break;
            case 'canny': result = canny(src); break;
            case 'inRange': result = inRange(src); break;
            case 'threshold': result = threshold(src); break;
            case 'adaptiveThreshold': result = adaptiveThreshold(src); break;
            case 'gaussianBlur': result = gaussianBlur(src); break;
            case 'bilateralFilter': result = bilateralFilter(src); break;
            case 'medianBlur': result = medianBlur(src); break;
            case 'sobel': result = sobel(src); break;
            case 'scharr': result = scharr(src); break;
            case 'laplacian': result = laplacian(src); break;
            case 'contours': result = contours(src); break;
            case 'calcHist': result = calcHist(src); break;
            case 'equalizeHist': result = equalizeHist(src); break;
            case 'backprojection': result = backprojection(src); break;
            case 'erosion': result = erosion(src); break;
            case 'dilation': result = dilation(src); break;
            case 'morphology': result = morphology(src); break;
            default: result = passThrough(src);
        }
        cv.imshow('canvasOutput_test', result);//src는 안에서 삭제처리합니다. src를 그대로 return하는 경우에는 밖에 리턴result에서 삭제
        stats.end();
        lastFilter = controls.filter;

        result.delete();//메모리해제한다.
        /*if(src && (src instanceof cv.Mat)){
            src.delete();
        }*/
        requestAnimationFrame(processVideo);
    }
    
    let stats = null;
    
    let filters = {
        'passThrough': 'Pass Through',
        'gray': 'Gray',
        'hsv': 'HSV',
        'canny': 'Canny Edge Detection',
        'inRange': 'In Range',
        'threshold': 'Threshold',
        'adaptiveThreshold': 'Adaptive Threshold',
        'gaussianBlur': 'Gaussian Blurring',
        'medianBlur': 'Median Blurring',
        'bilateralFilter': 'Bilateral Filtering',
        'sobel': 'Sobel Derivatives',
        'scharr': 'Scharr Derivatives',
        'laplacian': 'Laplacian Derivatives',
        'contours': 'Contours',
        'calcHist': 'Calculation',
        'equalizeHist': 'Equalization',
        'backprojection': 'Backprojection',
        'erosion': 'Erosion',
        'dilation': 'Dilation',
        'morphology': 'Morphology',
    };
    
    let filterName = document.getElementById('filterName');
    
    let controls;
    
    function initUI() {
        stats = new Stats();
        stats.showPanel(0);
        container.appendChild(stats.domElement);
        stats.domElement.style.position = 'absolute';
        stats.domElement.style.right = '0px';
        stats.domElement.style.top = '0px';
    
        controls = {
            filter: 'passThrough',
            setFilter: function(filter) {
                this.filter = filter;
                filterName.innerHTML = filters[filter];
            },
            passThrough: function() {
                this.setFilter('passThrough');
            },
            gray: function() {
                this.setFilter('gray');
            },
            hsv: function() {
                this.setFilter('hsv');
            },
            inRange: function() {
                this.setFilter('inRange');
            },
            inRangeLow: 75,
            inRangeHigh: 150,
            threshold: function() {
                this.setFilter('threshold');
            },
            thresholdValue: 100,
            adaptiveThreshold: function() {
                this.setFilter('adaptiveThreshold');
            },
            adaptiveBlockSize: 3,
            gaussianBlur: function() {
                this.setFilter('gaussianBlur');
            },
            gaussianBlurSize: 7,
            /*medianBlur: function() {
                this.setFilter('medianBlur');
            },
            medianBlurSize: 5,
            bilateralFilter: function() {
                this.setFilter('bilateralFilter');
            },
            bilateralFilterDiameter: 5,
            bilateralFilterSigma: 75,*/
            sobel: function() {
                this.setFilter('sobel');
            },
            sobelSize: 3,
            scharr: function() {
                this.setFilter('scharr');
            },
            laplacian: function() {
                this.setFilter('laplacian');
            },
            laplacianSize: 3,
            canny: function() {
                this.setFilter('canny');
            },
            cannyThreshold1: 150,
            cannyThreshold2: 300,
            cannyApertureSize: 3,
            cannyL2Gradient: false,
            contours: function() {
                this.setFilter('contours');
            },
            contoursMode: cv.RETR_CCOMP,
            contoursMethod: cv.CHAIN_APPROX_SIMPLE,
            calcHist: function() {
                this.setFilter('calcHist');
            },
            equalizeHist: function() {
                this.setFilter('equalizeHist');
            },
            backprojection: function() {
                this.setFilter('backprojection');
            },
            backprojectionRangeLow: 0,
            backprojectionRangeHigh: 150,
            morphology: function() {
                this.setFilter('morphology');
            },
            morphologyShape: cv.MORPH_RECT,
            morphologyOp: cv.MORPH_ERODE,
            morphologySize: 5,
            morphologyBorderType: cv.BORDER_CONSTANT,
        };
    
        let gui = new dat.GUI({autoPlace: false});
        let guiContainer = document.getElementById('guiContainer');
        guiContainer.appendChild(gui.domElement);
    
        let lastFolder = null;
        function closeLastFolder(folder) {
            if (lastFolder != null && lastFolder != folder) {
                lastFolder.close();
            }
            lastFolder = folder;
        }
    
        gui.add(controls, 'passThrough').name(filters['passThrough']).onChange(function() {
            closeLastFolder(null);
        });
    
        let colorConversion = gui.addFolder('Color Conversion');
        colorConversion.add(controls, 'gray').name(filters['gray']).onChange(function() {
            closeLastFolder(null);
        });
    
        colorConversion.add(controls, 'hsv').name(filters['hsv']).onChange(function() {
            closeLastFolder(null);
        });
    
        let inRange = colorConversion.addFolder(filters['inRange']);
        inRange.domElement.onclick = function() {
            closeLastFolder(inRange);
            controls.inRange();
        };
        inRange.add(controls, 'inRangeLow', 0, 255, 1).name('lower boundary');
        inRange.add(controls, 'inRangeHigh', 0, 255, 1).name('higher boundary');
    
        // let geometricTransformations = gui.addFolder('Geometric Transformations');
        // TODO
    
        let thresholding = gui.addFolder('Thresholding');
    
        let threshold = thresholding.addFolder(filters['threshold']);
        threshold.domElement.onclick = function() {
            closeLastFolder(threshold);
            controls.threshold();
        };
        threshold.add(controls, 'thresholdValue', 0, 200, 1).name('threshold value');
    
        let adaptiveThreshold = thresholding.addFolder(filters['adaptiveThreshold']);
        adaptiveThreshold.domElement.onclick = function() {
            closeLastFolder(adaptiveThreshold);
            controls.adaptiveThreshold();
        };
        adaptiveThreshold.add(
            controls, 'adaptiveBlockSize', 3, 99, 1).name('block size').onChange(
            function(value) {
                if (value % 2 === 0) controls.adaptiveBlockSize = value + 1;
            });
    
        let smoothing = gui.addFolder('Smoothing');
    
        let gaussianBlur = smoothing.addFolder(filters['gaussianBlur']);
        gaussianBlur.domElement.onclick = function() {
            closeLastFolder(gaussianBlur);
            controls.gaussianBlur();
        };
        gaussianBlur.add(
            controls, 'gaussianBlurSize', 7, 99, 1).name('kernel size').onChange(
            function(value) {
                if (value % 2 === 0) controls.gaussianBlurSize = value + 1;
            });
    
        /*let medianBlur = smoothing.addFolder(filters['medianBlur']);
        medianBlur.domElement.onclick = function() {
            closeLastFolder(medianBlur);
            controls.medianBlur();
        };
        medianBlur.add(
            controls, 'medianBlurSize', 3, 99, 1).name('kernel size').onChange(
            function(value) {
                if (value % 2 === 0) controls.medianBlurSize = value + 1;
            });
    
        let bilateralFilter = smoothing.addFolder(filters['bilateralFilter']);
        bilateralFilter.domElement.onclick = function() {
            closeLastFolder(bilateralFilter);
            controls.bilateralFilter();
        };
        bilateralFilter.add(controls, 'bilateralFilterDiameter', 1, 15, 1).name('diameter');
        bilateralFilter.add(controls, 'bilateralFilterSigma', 1, 255, 1).name('sigma');
        */
        let morphology = gui.addFolder('Morphology');
        morphology.domElement.onclick = function() {
            closeLastFolder(morphology);
            controls.morphology();
        };
        morphology.add(
            controls, 'morphologyOp',
            {'MORPH_ERODE': cv.MORPH_ERODE,
             'MORPH_DILATE': cv.MORPH_DILATE,
             'MORPH_OPEN ': cv.MORPH_OPEN,
             'MORPH_CLOSE': cv.MORPH_CLOSE,
             'MORPH_GRADIENT': cv.MORPH_GRADIENT,
             'MORPH_TOPHAT': cv.MORPH_TOPHAT,
             'MORPH_BLACKHAT': cv.MORPH_BLACKHAT}).name('operation');
        morphology.add(
            controls, 'morphologyShape',
            {'MORPH_RECT': cv.MORPH_RECT,
             'MORPH_CROSS': cv.MORPH_CROSS,
             'MORPH_ELLIPSE': cv.MORPH_ELLIPSE}).name('shape');
        morphology.add(
            controls, 'morphologySize', 1, 15, 1).name('kernel size').onChange(
            function(value) {
                if (value % 2 === 0) controls.morphologySize = value + 1;
            });
        morphology.add(
            controls, 'morphologyBorderType',
            {'BORDER_CONSTANT': cv.BORDER_CONSTANT,
             'BORDER_REPLICATE': cv.BORDER_REPLICATE,
             'BORDER_REFLECT': cv.BORDER_REFLECT,
             'BORDER_REFLECT_101': cv.BORDER_REFLECT_101}).name('boarder type');
    
        let gradients = gui.addFolder('Gradients');
        let sobel = gradients.addFolder(filters['sobel']);
        sobel.domElement.onclick = function() {
            closeLastFolder(sobel);
            controls.sobel();
        };
        sobel.add(controls, 'sobelSize', 3, 19, 1).name('kernel size').onChange(function(value) {
            if (value % 2 === 0) controls.sobelSize = value + 1;
        });
    
        gradients.add(controls, 'scharr').name(filters['scharr']).onChange(function() {
            closeLastFolder(null);
        });
    
        let laplacian = gradients.addFolder(filters['laplacian']);
        laplacian.domElement.onclick = function() {
            closeLastFolder(laplacian);
            controls.laplacian();
        };
        laplacian.add(
            controls, 'laplacianSize', 1, 19, 1).name('kernel size').onChange(
            function(value) {
                if (value % 2 === 0) controls.laplacianSize = value + 1;
            });
    
        let canny = gui.addFolder(filters['canny']);
        canny.domElement.onclick = function() {
            closeLastFolder(canny);
            controls.canny();
        };
        canny.add(controls, 'cannyThreshold1', 1, 500, 1).name('threshold1');
        canny.add(controls, 'cannyThreshold2', 1, 500, 1).name('threshold2');
        canny.add(controls, 'cannyApertureSize', 3, 7, 1).name('aperture size').onChange(
            function(value) {
                if (value % 2 === 0) controls.cannyApertureSize = value + 1;
            });
        canny.add(controls, 'cannyL2Gradient').name('l2 gradient');
    
        let contours = gui.addFolder(filters['contours']);
        contours.domElement.onclick = function() {
            closeLastFolder(contours);
            controls.contours();
        };
        contours.add(
            controls, 'contoursMode',
            {'RETR_EXTERNAL': cv.RETR_EXTERNAL,
             'RETR_LIST': cv.RETR_LIST,
             'RETR_CCOMP': cv.RETR_CCOMP,
             'RETR_TREE': cv.RETR_TREE}).name('mode');
        contours.add(
            controls, 'contoursMethod',
            {'CHAIN_APPROX_NONE': cv.CHAIN_APPROX_NONE,
             'CHAIN_APPROX_SIMPLE': cv.CHAIN_APPROX_SIMPLE,
             'CHAIN_APPROX_TC89_L1': cv.CHAIN_APPROX_TC89_L1,
             'CHAIN_APPROX_TC89_KCOS': cv.CHAIN_APPROX_TC89_KCOS}).name('method');
    
        let histograms = gui.addFolder('Histograms');
        histograms.add(controls, 'calcHist').name(filters['calcHist']).onChange(function() {
            closeLastFolder(null);
        });
        histograms.add(controls, 'equalizeHist').name(filters['equalizeHist']).onChange(function() {
            closeLastFolder(null);
        });
    
        let backprojection = histograms.addFolder(filters['backprojection']);
        backprojection.domElement.onclick = function() {
            closeLastFolder(backprojection);
            controls.backprojection();
        };
        backprojection.add(controls, 'backprojectionRangeLow', 0, 255, 1).name('range low');
        backprojection.add(controls, 'backprojectionRangeHigh', 0, 255, 1).name('range high');
    }
    
    function startCamera() {
        console.log('===카메라 스타트!');
        if (!streaming) {
            utils.clearError();
            utils.startCamera(resolution, onVideoStarted, 'videoInput');
        } else {
            utils.stopCamera();
            onVideoStopped();
        }
    }
    
    function onVideoStarted() {
        console.log('비디오 스타트!!:');
        height = testvideo.videoHeight;
        width = testvideo.videoWidth;
        testvideo.setAttribute('width', width);
        testvideo.setAttribute('height', height);
        console.log('test videosss:',height,width,testvideo);
        streaming = true;
        vc = new cv.VideoCapture(testvideo);
        console.log('vcwhatsss: what vc:',vc);
        startVideoProcessing();
    }
    
    function stopVideoProcessing() {
        //if (src != null && !src.isDeleted()) src.delete();
        //if (dstC1 != null && !dstC1.isDeleted()) dstC1.delete();
        //if (dstC3 != null && !dstC3.isDeleted()) dstC3.delete();
        //if (dstC4 != null && !dstC4.isDeleted()) dstC4.delete();
    }
    
    function onVideoStopped() {
        console.log('비디오종료!!');
        if (!streaming) return;
        stopVideoProcessing();
        document.getElementById('canvasOutput_test').getContext('2d').clearRect(0, 0, width, height);
        streaming = false;
    }
    
    utils.loadOpenCv(() => {
        initUI();
        startCamera();
        onOpenCvReady();
    });
</script>
<!--<script async src='public/opencv.js' onload='onOpenCvReady()'></script>-->
</body>
</html>